---
title: 'What exactly is an "expected point"? (part 1)'
description: 'Calculating and comparing expected points from different expected goals sources'
author:
  - name: Tony ElHabr
    url: 'https://twitter.com/TonyElHabr'
date: 2022-09-05
categories:
  - r
  - soccer
output: 
  distill::distill_article:
    toc: true
    toc_depth: 4
    self_contained: false
preview: calib.png
twitter:
  site: '@TonyElHabr'
  creator: '@TonyElHabr'
---

```{r setup, include=F, echo=F, cache=F}
knitr::opts_chunk$set(
  include = TRUE,
  echo = TRUE,
  cache = FALSE,
  eval = FALSE,
  cache.lazy = FALSE,
  fig.show = 'hide',
  fig.align = 'center',
  fig.width = 8,
  fig.asp = 0.75,
  fig.retina = 2,
  warning = FALSE,
  message = FALSE
)
```

## Introduction

[Expected goals (xG)](https://theanalyst.com/na/2021/07/what-are-expected-goals-xg/) in soccer have gone mainstream and are no longer cool to talk about.

<blockquote class="twitter-tweet">

<p lang="en" dir="ltr">

What exactly is an " expected goal "? Who decides the criteria ? Is there a list of" expected goal scorers " ? Or even " unexpected ones " ?

</p>

--- Ian Darke (@IanDarke) <a href="https://twitter.com/IanDarke/status/1341904890914885641?ref_src=twsrc%5Etfw">December 24, 2020</a>

</blockquote>

```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```
So let's talk about [expected points (xPts)](https://www.bettingodds.com/news/what-are-expected-points-xp-football-betting). The one sentence explainer for xPts: it's a number between 0 and 3 assigned to each team in a match that we estimate from the xG of each shot in the match. Teams that accumulate more xG than their opponents in the match are more likely to have xPts closer to 3, i.e. the points awarded for a win, and those that accumulate less than their opponents are more likely to earn xPts closer to 0. xPts is convenient for translating a team's xG (relative to it's opponents) to the team's expected placement in the standings.

While [several](https://luke-beggs.medium.com/creating-an-expected-points-xp-calculator-for-football-matches-ce4edd18d16f) [outlets](https://theshortfuse.sbnation.com/2017/11/15/16655916/how-to-calculate-xpoints-analysis-stats-xg) have described computing expected points with simulation, simulation is actually not necessary if you have the xG for every shot taken in a match.[^1] For example, let's say team A shoots six times with an xG of 0.1 for each shot, and team B shoots three shots with xG's of 0.1, 0.2, and 0.3 respectively. Given these goal probabilities, we can analytically compute the probabilities of (1) team A winning, (2) team B winning, and (3) a draw as follows.[^2]

[^1]: Now, if you desire the statistical properties that simulation offers, such as an estimation of error, that's understandable; however, in write-ups that I've seen, such is not mentioned explicitly. Additionally, if one chooses to go down the simulation route because they believe that it helps to suppress flaws with the xG model, that's also understandable. On the other hand, the analytical approach I present should present nearly identical results to that which one would find with simulation, and it offers the advantage of being much faster.

[^2]: How does this work? Under the assumption that xG comes from a Poisson binomial distributions, we look at all combinations of makes and misses of the shots and compare the relative proportion of instances in which one team's number of success, i.e. goals, is greater than, equal to, or less than their opponent's.

```{r}
#| label: ex-probs
#| eval: false
library(poibin)
library(gdata)
xg_a <- rep(0.1, 6)
xg_b <- c(0.1, 0.2, 0.3)

probs_a <- poibin::dpoibin(seq.int(0, length(xg_a)), xg_a)
probs_b <- poibin::dpoibin(seq.int(0, length(xg_b)), xg_b)

outer_prod <- outer(probs_a, probs_b)
p_a <- sum(gdata::upperTriangle(outer_prod))
p_b <- sum(gdata::lowerTriangle(outer_prod))
p_draw <- sum(diag(outer_prod))
round(c(p_a, p_b, p_draw), 2)
#> [1] 0.30 0.28 0.42
```

The calculation of xPts is straightforward once the match outcome probabilities are computed.

```{r}
#| label: ex-pts
xpts_a <- 3 * p_a + 1 * p_draw
xpts_b <- 3 * p_b + 1 * p_draw
round(c(xpts_a, xpts_b), 2)
#> [1] 1.31 1.27
```

For this example, we arrive at the interesting result that, despite the two teams total xG being equal (=0.6), team A has a slightly higher probability of winning. There have been plenty of [explanations](https://hockey-graphs.com/2018/12/19/some-people-were-wrong-on-twitter/) on this "quality vs. quantity" phenomenon, so I won't go into it in detail. Nonetheless, this simple example illustrates why it can be useful to translate xG into another form---doing so provides a better perspective on match results and team placement in the standings, which is determined by points.

### Objectives

So we've gone over what expected points are and why they're important. Now we set out to do the following.

1.  **Calculate xPts from shot xG for multiple seasons of data.** We'll limit the scope to the 2020/21 and 2021/22 seasons for the English Premier League.[^3]
2.  **Compare the calibration of the understat and fotmob match outcome probabilities.** `{worldfootballR}` makes it easy for us to get xG from both [understat](https://understat.com/) and [fotmob](https://www.fotmob.com/), and it should be interesting to compare the the predictive performance of the two models.
3.  **Compare predictions of actual season-long points using xPts that we derive from understat and fotmob xG.** In particular, we'll be interested to see if our conclusions regarding the better source for xG here matches the conclusions for (2).

[^3]: We've limited the scope for several reasons: (1) fotmob only has complete xG data for the 2020/21 and 2021/22 seasons as of writing, (2) I didn't want to have to map team names across the two data sources for a ton of teams; and (3) of all league, I'm most interested in the EPL ðŸ˜„.

## Analysis

### 1. Calculating xPts from xG

Let's start by using the `load_understat_league_shots()` function from `{worldfootballR}` to retrieve understat xG by shot.

```{r}
#| label: load_understat_league_shots
#| eval: false
library(readr)
library(dplyr)
library(tibble)
library(tidyr)
library(stringr)
library(lubridate)
library(worldfootballR) ## version: 0.5.12.5000
library(janitor)

## manually created CSV with 3 columns: team_538, team_understat, team_fotmob.
##   use the team_538 name to be consistent across sources.
##   CSV: https://raw.githubusercontent.com/tonyelhabr/sports_viz/master/59-xg_xpoints/team_mapping.csv
team_mapping <- 'team_mapping.csv' |> readr::read_csv()

rename_teams <- function(df, src) {
  team_src <- sprintf('team_%s', src)
  df |> 
    dplyr::left_join(
      team_mapping |> 
        dplyr::select(.data$team_538, .data[[team_src]]),
      by = c('home_team' = team_src)
    ) |> 
    dplyr::select(-.data$home_team) |> 
    dplyr::rename(home_team = .data$team_538) |> 
    dplyr::left_join(
      team_mapping |> 
        dplyr::select(.data$team_538, .data[[team_src]]),
      by = c('away_team' = team_src)
    ) |> 
    dplyr::select(-.data$away_team) |> 
    dplyr::rename(away_team = .data$team_538) |> 
    dplyr::mutate(
      team = ifelse(is_home, home_team, away_team),
      opponent = ifelse(is_home, away_team, home_team)
    ) |> 
    dplyr::select(-c(home_team, away_team)) 
}

convert_understat_year_to_season <- function(x) {
  sprintf('%s/%s', x, stringr::str_sub(x + 1, 3, 4))
}

## we'll use all of the shots later when exporing understat data only
all_understat_shots <- worldfootballR::load_understat_league_shots('EPL') |> 
  tibble::as_tibble() |> 
  ## camelcase like "xG" is for Java scrubs
  janitor::clean_names() |> 
  filter(season <= 2021) |> 
  ## transmute = select + mutate
  dplyr::transmute(
    match_id,
    ## "2021/2022" format so that we have a clear, consistent way to represent season
    dplyr::across(season, convert_understat_year_to_season),
    ## to convert "2020-09-12 11:30:00" to a date ("2020-09-12")
    dplyr::across(date, lubridate::date),
    home_team,
    away_team,
    is_home = h_a == 'h',
    xg = x_g
  ) |>
  rename_teams('understat') |> 
  dplyr::arrange(season, date, team)

## but when comparing understat with fotmob, we'll need to limit the seasons to just
##   those that both sources have
understat_shots <- all_understat_shots |> 
  dplyr::filter(season >= 2020)
understat_shots
#> # A tibble: 19,010 Ã— 7
#>    match_id season  date       is_home     xg team    opponent
#>       <dbl> <chr>   <date>     <lgl>    <dbl> <chr>   <chr>   
#>  1    14086 2020/21 2020-09-12 FALSE   0.0644 Arsenal Fulham  
#>  2    14086 2020/21 2020-09-12 FALSE   0.649  Arsenal Fulham  
#>  3    14086 2020/21 2020-09-12 FALSE   0.758  Arsenal Fulham  
#>  4    14086 2020/21 2020-09-12 FALSE   0.110  Arsenal Fulham  
#>  5    14086 2020/21 2020-09-12 FALSE   0.0572 Arsenal Fulham  
#>  6    14086 2020/21 2020-09-12 FALSE   0.136  Arsenal Fulham  
#>  7    14086 2020/21 2020-09-12 FALSE   0.0817 Arsenal Fulham  
#>  8    14086 2020/21 2020-09-12 FALSE   0.506  Arsenal Fulham  
#>  9    14086 2020/21 2020-09-12 FALSE   0.0943 Arsenal Fulham  
#> 10    14086 2020/21 2020-09-12 FALSE   0.0526 Arsenal Fulham  
#> # â€¦ with 19,000 more rows
```

We can use `load_fotmob_match_details()` to get fotmob's shot xG in a similar fashion.[^4]

[^4]: Note that there are three additional shots in the fotmob data. There's no simple solution to resolving this data discrepancy since we don't have matching shot identifiers in the two data sets ðŸ¤·.

```{r}
#| label: load_fotmob_match_details
#| eval: false
fotmob_shots <- worldfootballR::load_fotmob_match_details(
  country = 'ENG',
  league_name = 'Premier League'
) |> 
  dplyr::mutate(
    ## to convert strings from 'Sat, Sep 12, 2020, 11:30 UTC' to a date
    date = strptime(match_time_utc, '%a, %b %d, %Y, %H:%M UTC', tz = 'UTC') |> lubridate::date(),
    ## fotmob's parent_league_season always reflects the current season, so we need to manually
    ##   define the season from the date. we would certainly want a more automated approach
    ##   if working with more seasons and more leagues.
    season = dplyr::case_when(
      date >= lubridate::ymd('2020-09-12') & date <= lubridate::ymd('2021-05-23') ~ '2020/21',
      date >= lubridate::ymd('2021-08-13') & date <= lubridate::ymd('2022-05-22') ~ '2021/22',
      TRUE ~ NA_character_
    )
  ) |> 
  ## the NAs are for 2022/2023 (incomplete as of writing) and the partial data for 2019/2020
  tidyr::drop_na(season) |> 
  dplyr::transmute(
    match_id,
    season,
    date,
    home_team,
    away_team,
    is_home = team_id == home_team_id,
    ## some shots with NAs for some reason
    xg = coalesce(expected_goals, 0)
  ) |>
  rename_teams('fotmob') |> 
  dplyr::arrange(season, date, team)
fotmob_shots
#> # A tibble: 19,013 Ã— 7
#>    match_id season  date       is_home     xg team    opponent
#>       <int> <chr>   <date>     <lgl>    <dbl> <chr>   <chr>   
#>  1  3411352 2020/21 2020-09-12 FALSE   0.0602 Arsenal Fulham  
#>  2  3411352 2020/21 2020-09-12 FALSE   0.737  Arsenal Fulham  
#>  3  3411352 2020/21 2020-09-12 FALSE   0.845  Arsenal Fulham  
#>  4  3411352 2020/21 2020-09-12 FALSE   0.0879 Arsenal Fulham  
#>  5  3411352 2020/21 2020-09-12 FALSE   0.0443 Arsenal Fulham  
#>  6  3411352 2020/21 2020-09-12 FALSE   0.131  Arsenal Fulham  
#>  7  3411352 2020/21 2020-09-12 FALSE   0.0916 Arsenal Fulham  
#>  8  3411352 2020/21 2020-09-12 FALSE   0.310  Arsenal Fulham  
#>  9  3411352 2020/21 2020-09-12 FALSE   0.0531 Arsenal Fulham  
#> 10  3411352 2020/21 2020-09-12 FALSE   0.0631 Arsenal Fulham  
#> # â€¦ with 19,003 more rows
```

Alright, now the fun part. We functionalize the code from the example for calculating the probability that xG will result in 0, 1, 2, etc. goals (up to the number of shots taken).

```{r}
#| label: calculate_permuted_xg
#| eval: false
library(purrr)
permute_xg <- function(xg) {
  n <- length(xg)
  x <- seq.int(0, n)
  poibin::dpoibin(x, xg)
}

calculate_permuted_xg <- function(df) {
  df |> 
    dplyr::group_by(dplyr::across(c(dplyr::everything(), -xg))) |> 
    dplyr::summarize(dplyr::across(xg, ~list(.x))) |> 
    dplyr::mutate(
      prob = purrr::map(xg, ~permute_xg(.x))
    ) |> 
    dplyr::select(-c(xg)) |> 
    tidyr::unnest(cols = c(prob)) |> 
    dplyr::group_by(dplyr::across(-c(prob))) |>
    dplyr::mutate(
      g = dplyr::row_number() - 1L
    ) |>
    dplyr::ungroup() |> 
    dplyr::arrange(match_id, is_home, g)
}

understat_permuted_xg <- understat_shots |> calculate_permuted_xg()
fotmob_permuted_xg <- fotmob_shots |> calculate_permuted_xg()

## just one of the variables. the other one looks the same, with different values for prob
understat_permuted_xg
#> # A tibble: 20,530 Ã— 8
#>    match_id season  date       is_home team    opponent       prob     g
#>       <dbl> <chr>   <date>     <lgl>   <chr>   <chr>         <dbl> <int>
#>  1    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.0180         0
#>  2    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.124          1
#>  3    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.298          2
#>  4    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.320          3
#>  5    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.172          4
#>  6    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.0543         5
#>  7    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.0110         6
#>  8    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.00150        7
#>  9    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.000141       8
#> 10    14086 2020/21 2020-09-12 FALSE   Arsenal Fulham   0.00000917     9
#> # â€¦ with 20,520 more rows
```

Next, we identify all possible goal combinations using xG as "weights" to compute the relative likelihood of each combination, and then analytically calculate the probabilities of winning, losing, and drawing.

```{r}
#| label: summarize_permuted_xg_by_match
#| eval: false
summarize_pivoted_permuted_xg <- function(prob_away, prob_home) {
  outer_prod <- outer(prob_away, prob_home)
  p_draw <- sum(diag(outer_prod), na.rm = TRUE)
  p_home <- sum(gdata::upperTriangle(outer_prod), na.rm = TRUE)
  p_away <- sum(gdata::lowerTriangle(outer_prod), na.rm = TRUE)
  list(
    draw = p_draw,
    home = p_home,
    away = p_away
  )
}

summarize_permuted_xg_by_match <- function(df) {
  pivoted <- df |>
    dplyr::transmute(
      match_id,
      season,
      date,
      g,
      is_home = ifelse(is_home, 'home', 'away'),
      prob
    ) |>
    tidyr::pivot_wider(
      names_from = is_home,
      names_prefix = 'prob_',
      values_from = prob,
      values_fill = 0L
    )
  
  pivoted |> 
    dplyr::select(match_id, season, date, prob_away, prob_home) |>
    dplyr::group_by(match_id, season, date) |> 
    dplyr::summarize(
      dplyr::across(dplyr::starts_with('prob_'), ~list(.x))
    ) |> 
    dplyr::ungroup() |> 
    dplyr::inner_join(
      df |> distinct(match_id, team, opponent, is_home),
      by = 'match_id'
    ) |> 
    dplyr::mutate(
      prob = map2(prob_away, prob_home, summarize_pivoted_permuted_xg)
    ) |> 
    dplyr::select(-starts_with('prob_')) |> 
    tidyr::unnest_wider(prob, names_sep = '_') |> 
    dplyr::mutate(
      prob_win = ifelse(is_home, prob_home, prob_away),
      prob_lose = ifelse(is_home, prob_away, prob_home),
      xpts = 3 * prob_win + 1 * prob_draw
    ) |> 
    dplyr::select(-c(prob_home, prob_away))
}

understat_xpts_by_match <- understat_permuted_xg |> summarize_permuted_xg_by_match()
fotmob_xpts_by_match <- fotmob_permuted_xg |> summarize_permuted_xg_by_match()

## just one of the variables. the other looks the same, with different values for prob* and xpts
understat_xpts_by_match |> 
  dplyr::select(-c(season, match_id, is_home)) |>
  dplyr::mutate(dplyr::across(c(dplyr::starts_with('prob_'), xpts), round, 2))
#> # A tibble: 1,520 Ã— 7
#>    date       team              opponent          prob_dâ€¦Â¹ prob_â€¦Â² prob_â€¦Â³  xpts
#>    <date>     <chr>             <chr>                <dbl>   <dbl>   <dbl> <dbl>
#>  1 2020-09-12 Arsenal           Fulham                0.03    0.97    0     2.93
#>  2 2020-09-12 Fulham            Arsenal               0.03    0       0.97  0.04
#>  3 2020-09-12 Southampton       Crystal Palace        0.3     0.31    0.39  1.22
#>  4 2020-09-12 Crystal Palace    Southampton           0.3     0.39    0.31  1.48
#>  5 2021-01-12 Manchester United Burnley               0.3     0.52    0.18  1.86
#>  6 2021-01-12 Burnley           Manchester United     0.3     0.18    0.52  0.84
#>  7 2021-01-20 Aston Villa       Manchester City       0.04    0.01    0.95  0.07
#>  8 2021-01-20 Manchester City   Aston Villa           0.04    0.95    0.01  2.89
#>  9 2020-09-12 Leeds United      Liverpool             0.03    0       0.97  0.04
#> 10 2020-09-12 Liverpool         Leeds United          0.03    0.97    0     2.93
#> # â€¦ with 1,510 more rows, and abbreviated variable names Â¹â€‹prob_draw, Â²â€‹prob_win,
#> #   Â³â€‹prob_lose
```

If there was any doubt about the expected points calculation, note that understat offers xPts directly in their data. The mean absolute error of our calculation of xPts with theirs is \~0.02.

```{r}
#| label: compare-xpts-with-understat-raw
#| eval: false
library(understatr)

all_raw_understat_xpts_by_match <- 2014:2021 |> 
  rlang::set_names() |> 
  purrr::map_dfr(
    ~understatr::get_league_teams_stats('EPL', .x),
    .id = 'season'
  ) |> 
  dplyr::mutate(
    season = convert_understat_year_to_season(as.integer(season))
  ) |> 
  dplyr::inner_join(
    team_mapping |> dplyr::select(team_538, team_understat),
    by = c('team_name' = 'team_understat')
  ) |> 
  dplyr::select(-team_name) |> 
  dplyr::rename(team = team_538) |> 
  dplyr::select(
    season,
    date,
    team,
    result,
    pts,
    raw_xpts = xpts,
    xg = xG
  )

raw_understat_xpts_by_match <- all_raw_understat_xpts_by_match |> 
  dplyr::inner_join(
    understat_xpts_by_match |> dplyr::select(season, date, team, xpts),
    by = c('season', 'date', 'team')
  ) |> 
  mutate(
    xptsd = raw_xpts - xpts
  ) |> 
  arrange(season, date, team)
raw_understat_xpts_by_match
#> # A tibble: 1,520 Ã— 9
#>    season  date       team            result   pts raw_xâ€¦Â¹    xg   xpts    xptsd
#>    <chr>   <date>     <chr>           <chr>  <int>   <dbl> <dbl>  <dbl>    <dbl>
#>  1 2020/21 2020-09-12 Arsenal         w          3  2.89   2.16  2.93   -3.40e-2
#>  2 2020/21 2020-09-12 Crystal Palace  w          3  1.48   1.40  1.48   -1.08e-3
#>  3 2020/21 2020-09-12 Fulham          l          0  0.0587 0.126 0.0405  1.82e-2
#>  4 2020/21 2020-09-12 Leeds United    l          0  0.0434 0.270 0.0440 -5.77e-4
#>  5 2020/21 2020-09-12 Liverpool       w          3  2.93   3.15  2.93    1.03e-3
#>  6 2020/21 2020-09-12 Newcastle       w          3  2.05   1.66  2.03    1.86e-2
#>  7 2020/21 2020-09-12 Southampton     l          0  1.22   1.26  1.22   -5.44e-4
#>  8 2020/21 2020-09-12 West Ham United l          0  0.700  0.861 0.717  -1.71e-2
#>  9 2020/21 2020-09-13 Everton         w          3  1.74   1.27  1.74    5.98e-3
#> 10 2020/21 2020-09-13 Leicester City  w          3  2.91   2.96  2.91    6.14e-4
#> # â€¦ with 1,510 more rows, and abbreviated variable name Â¹â€‹raw_xpts

## mean absolute error
round(mean(abs(raw_understat_xpts_by_match$xptsd)), 3)
#> [1] 0.022
```

### 2. Match predictive performance[^5]

[^5]: Using the adjective "predictive" is a little misleading, since we're not actually making predictions out-of-sample. Rather, we're using models based on xG to evaluate which xG data source better explains the observed results.

As one might guess, the match outcome probabilities implied by the xG from understat and fotmob are strongly correlated.

```{r}
#| label: xpts_by_match
#| eval: false
rename_xpts_by_match <- function(df, src) {
  df |> 
    dplyr::select(season, date, team, dplyr::starts_with('prob_'), xpts) |> 
    dplyr::rename_with(
      ~sprintf('%s_%s', .x, src), c(dplyr::starts_with('prob_'), xpts)
    )
}

xpts_by_match <- raw_understat_xpts_by_match |> 
  dplyr::select(season, date, team, result, pts) |> 
  dplyr::inner_join(
    understat_xpts_by_match |> rename_xpts_by_match('understat'),
    by = c('season', 'date', 'team')
  ) |> 
  dplyr::inner_join(
    fotmob_xpts_by_match |> rename_xpts_by_match('fotmob'),
    by = c('season', 'date', 'team')
  )

cor_draw <- cor(xpts_by_match$prob_draw_fotmob, xpts_by_match$prob_draw_understat)
cor_win <- cor(xpts_by_match$prob_win_fotmob, xpts_by_match$prob_win_understat)
cor_lose <- cor(xpts_by_match$prob_lose_fotmob, xpts_by_match$prob_lose_understat)
round(c(cor_draw, cor_win, cor_lose), 3)
#> [1] 0.906 0.958 0.958
```

Note that the win and loss correlations are identical. This is due to the symmetric nature of the data---we have two records for each match, one from each team's perspective.[^6]

[^6]: Home field advantage is treated as a feature instead of defined directly via columns, i.e. `home_team`, `home_score`, etc., which is good practice in general.

#### Predicting match outcomes with binary logistic regression

Now let's compare how "good" the implied probabilities from the two sources are. To do this, we'll create binary logistic regression models to predict a given outcome and compute:

1.  the [mean squared error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error);
2.  the [brier skill score (BSS)](https://en.wikipedia.org/wiki/Brier_score#Brier_Skill_Score_(BSS)), treating the empirical proportion of the specified outcome as the reference.[^7][^8]
3.  a [calibration plot](https://changhsinlee.com/python-calibration-plot/), grouping predictions into "buckets" at every 5%.

[^7]: Draws occur for 22.5% of matches in the data set, and wins and losses occur in 38.8% of matches each.

[^8]: Personally, I tend to rely on BSS wherever I can. Not only is it more interpretable---it's a number between 0 and 1, while MSE can take on any value, depending on the context---I like that it forces one to compare to a baseline, which is a good principle in general.

```{r}
#| label: diagnose_prob_by_match
#| eval: false
result_props <- xpts_by_match |> 
  dplyr::count(result) |> 
  dplyr::mutate(prop = n / sum(n))

compute_mse <- function(truth, estimate) {
  mean((truth - estimate)^2)
}

diagnose_prob_by_match <- function(src, result) {
  
  df <- xpts_by_match |> 
    dplyr::mutate(
      result = ifelse(result == !!result, 1L, 0L) |> factor()
    )
  
  result_name <- switch(
    result,
    'w' = 'win',
    'l' = 'lose',
    'd' = 'draw'
  )
  col <- sprintf('prob_%s_%s', result_name, src)
  
  fit <- glm(
    df$result ~ df[[col]],
    family = 'binomial'
  )
  
  probs <- tibble::tibble(
    result_num = as.numeric(df$result) - 1,
    .prob = unname(predict(fit, type = 'response'))
  )
  
  n_buckets <- 20
  alpha <- 0.05
  calib <- probs |>
    dplyr::mutate(
      dplyr::across(.prob, ~round(.x * n_buckets) / n_buckets)
    ) |>
    dplyr::group_by(.prob) |>
    dplyr::summarize(
      ## Jeffreys' prior
      ci_lower = qbeta(alpha / 2, sum(result_num) + 0.5, dplyr::n() - sum(result_num) + 0.5),
      ci_upper = qbeta(1 - alpha / 2, sum(result_num) + 0.5, dplyr::n() - sum(result_num) + 0.5),
      actual = sum(result_num) / n(),
      n = dplyr::n()
    ) |> 
    dplyr::ungroup()
  
  mse <- compute_mse(probs$result_num, probs$.prob)
  
  ref_prob <- result_props |> 
    dplyr::filter(result == !!result) |> 
    dplyr::pull(prop)
  
  ref_mse <- compute_mse(probs$result_num, ref_prob)
  bss <- 1 - (mse / ref_mse)
  
  list(
    calib = calib,
    mse = mse,
    bss = bss
  )
}

diagnostics <- crossing(
  result = c('w', 'd'),
  src = c('understat', 'fotmob')
) |> 
  mutate(
    diagnostics = map2(src, result, diagnose_prob_by_match)
  ) |> 
  unnest_wider(diagnostics)
diagnostics
#> # A tibble: 4 Ã— 5
#>   result src       calib               mse    bss
#>   <chr>  <chr>     <list>            <dbl>  <dbl>
#> 1 d      fotmob    <tibble [10 Ã— 5]> 0.170 0.0268
#> 2 d      understat <tibble [10 Ã— 5]> 0.166 0.0466
#> 3 w      fotmob    <tibble [17 Ã— 5]> 0.173 0.270 
#> 4 w      understat <tibble [17 Ã— 5]> 0.162 0.317
```

The MSE (where lower is "better") and the BSS (where higher is "better") lead us to same conclusion---the models based on understat's xG slightly outperform the one based on fotmob's xG.

Moreover, looking at the calibration plot, the understat model predictions seem to stick closer to the 45 degree slope, which represents perfect calibration.[^9]

[^9]: Plotting code is omitted here since it's not relevant to our analysis.

```{r}
#| label: theming
#| eval: false
#| include: false
library(ggplot2)
library(extrafont)
blackish_background <- '#1c1c1c'
gray_points <- '#4d4d4d'
gray_text <- '#999999'

font <- 'Karla'
extrafont::loadfonts(quiet = TRUE)
theme_set(theme_minimal())
theme_update(
  text = element_text(family = font),
  title = element_text(size = 20, color = 'white'),
  plot.title = element_text(face = 'bold', size = 16, color = 'white'),
  plot.title.position = 'plot',
  plot.subtitle = element_text(size = 14, color = '#f1f1f1'),
  axis.text = element_text(color = 'white', size = 14),
  axis.title = element_text(size = 14, color = 'white', face = 'bold', hjust = 0.99),
  axis.line = element_blank(),
  legend.text = element_text(size = 14, color = 'white'),
  legend.position = 'top',
  panel.grid.major = element_line(color = gray_points),
  panel.grid.minor = element_line(color = gray_points),
  panel.grid.minor.x = element_blank(),
  panel.grid.minor.y = element_blank(),
  plot.margin = margin(10, 10, 10, 10),
  strip.text = element_text(size = 14, color = 'white', face = 'bold', hjust = 0),
  plot.background = element_rect(fill = blackish_background, color = blackish_background),
  plot.caption = element_text(color = 'white', hjust = 1, size = 10, face = 'italic'),
  plot.caption.position = 'plot',
  panel.background = element_rect(fill = blackish_background, color = blackish_background)
)
update_geom_defaults('point', list(color = 'white'))
```

```{r}
#| label: p_calib
#| eval: false
#| include: false
library(ggplot2)
library(scales)

calib |> 
  ggplot2::ggplot() +
  ggplot2::aes(x = .prob, y = actual, color = src) +
  ggplot2::geom_point(
    aes(size = n),
    position = ggplot2::position_dodge(width = 0.05)
  ) +
  ggplot2::geom_errorbar(
    ggplot2::aes(
      ymin = ci_lower, 
      ymax = ci_upper
    ), 
    position = ggplot2::position_dodge(width = 0.05),
    width = 0.025
  ) +
  ggplot2::geom_abline(slope = 1, intercept = 0, color = 'white') +
  ggplot2::scale_x_continuous(labels = scales::percent, limits = c(-0.025, 1.025)) +
  ggplot2::scale_y_continuous(labels = scales::percent, limits = c(-0.025, 1.025)) +
  ggplot2::facet_wrap(~result) +
  guides(
    color = ggplot2::guide_legend('Source', override.aes = list(size = 3)),
    size = ggplot2::guide_legend('Sample size')
  ) +
  ggplot2::labs(
    title = 'Calibration of implied match outcome probabilities',
    subtitle = '2021/22 - 2021/22 English Premier League',
    x = 'Probability',
    y = 'Actual Proportion',
    caption = 'Error bars represent a 95% posterior credible interval for the mean predicted chance using a beta-binomial conjugate (i.e. Jeffreys\' Prior).\nLoss calibration is redundant with win calibration.'
  )
```

```{r}
#| label: p_calib-save
#| eval: false
#| include: false
path_calib <- file.path(dir_proj, 'calib.png')

ggsave(
  filename = path_calib,
  width = 10,
  height = 7.5
)
```

![](calib.png)

#### Predicting points with linear regression

Alternatively, we could regress points on expected points. For linear regression, we can use the [root mean squared error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation) (where lower is "better") and [R squared](https://en.wikipedia.org/wiki/Coefficient_of_determination) (where higher is "better") to compare the models.

```{r}
#| label: compute_xpts_by_match_rmse
#| eval: false
compute_rmse <- function(truth, estimate) {
  sqrt(mean((truth - estimate)^2))
}

diagnose_xpts_by_match <- function(src) {
  
  col <- sprintf('xpts_%s', src)
  fit <- lm(xpts_by_match$pts ~ xpts_by_match[[col]])
  
  pred <- predict(fit)
  
  tibble::tibble(
    rmse = compute_rmse(xpts_by_match$pts, pred),
    r2 = summary(fit)r.squared
  )
}

c('understat', 'fotmob') |> 
  set_names() |> 
  map_dfr(diagnose_xpts_by_match, .id = 'src')
#> # A tibble: 2 Ã— 3
#>   src        rmse    r2
#>   <chr>     <dbl> <dbl>
#> 1 understat  1.06 0.374
#> 2 fotmob     1.10 0.322
```

The understat model proves to be better by both metrics, having a lower RMSE and higher R squared than the fotmob model.

#### Predicting match outcomes with multinomial logistic regression

Personally, I don't like predicting points directly like this since it's a discrete variable that can only take on three values (0, 1, and 3). If we're going to predict points instead of a probability, I think the better approach is to run a multinomial logistic regression and convert the predicted probabilities to expected points.

```{r}
#| label: compute_implied_xpts_by_match_rmse
#| eval: false
library(nnet)
diagnose_implied_xpts_by_match <- function(src) {
  
  col_win <- sprintf('prob_win_%s', src)
  col_draw <- sprintf('prob_draw_%s', src)
  fit <- nnet::multinom(
    xpts_by_match$result ~ xpts_by_match[[col_win]] + xpts_by_match[[col_draw]],
    trace = FALSE
  )
  probs <- predict(fit, type = 'probs') |> tibble::as_tibble()
  preds <- 3 * probs$w + 1 * probs$d
  
  tibble::tibble(
    rmse = compute_rmse(xpts_by_match$pts, preds),
    r2 = cor(xpts_by_match$pts, preds)^2
  )
}

c('understat', 'fotmob') |> 
  set_names() |> 
  map_dfr(diagnose_implied_xpts_by_match, .id = 'src')
#> # A tibble: 2 Ã— 3
#>   src        rmse    r2
#>   <chr>     <dbl> <dbl>
#> 1 understat  1.06 0.374
#> 2 fotmob     1.10 0.321
```

Again, we see that understat has a lower RMSE and higher R squared with both approaches to predicting points. The implication that understat performs slighlty better agrees with the binary logistic regression models for predicting match outcome probabilities and the linear regression models for predicting points.

Overall, we might say that understat seems to be the better of the two xG sources for explaining individual match results.

### 3. Season predictive performance

How do the understat and fotmob models fare if we aggregate up the expected points to the season level and predict actual points?[^10]

[^10]: Note that aggregating match-level probabilities to the season-level is not a statistically valid way to use the probabilities, which are intended to be treated independently.

```{r}
xpts_by_season <- xpts_by_match |> 
  group_by(season, team) |> 
  summarize(
    across(c(pts, starts_with('xpts')), sum)
  ) |> 
  ungroup()
xpts_by_season

diagnose_xpts_by_season <- function(src) {
  
  col <- sprintf('xpts_%s', src)
  fit <- lm(xpts_by_season$pts ~ xpts_by_season[[col]])
  
  preds <- predict(fit)
  
  tibble::tibble(
    rmse = compute_rmse(xpts_by_match$pts, preds),
    r2 = summary(fit)$r.squared
  )
}

c('understat', 'fotmob') |> 
  set_names() |> 
  map_dfr(diagnose_xpts_by_season, .id = 'src')
#> # A tibble: 2 Ã— 3
#>   src        rmse    r2
#>   <chr>     <dbl> <dbl>
#> 1 understat  53.9 0.845
#> 2 fotmob     53.8 0.825
```

The results are closer than those at the match-level. In fact, fotmob barely edges out understat in terms of RMSE xPts, although understat outperforms fotmob according to R squared by a relatively comfortable 0.02. It's harder to make a general statement regarding which data source provides better xG for explaining season-long expected points, but we might lean in favor of understat again.

## Conclusion

***SARCASM ACTIVATED***

Alas, we find that understat's xG model seems to outperform fotmob's in terms of explaining match results and season-long point totals, so no one should ever use fotmob's site again! As my long-time dedicated follower know (all three of you), I am not one to shy away from calling out data providers on their B.S. I am glad to continue to live up to my reputation.

<blockquote class="twitter-tweet">

<p lang="en" dir="ltr">

Fine, since no one has been brave enough to do it, I will. I'm calling out Opta for stat-padding for attackers, giving them more credit than StatsBomb for aerial duel success. <a href="https://t.co/ZOeCg320qp">pic.twitter.com/ZOeCg320qp</a>

</p>

--- Tony (@TonyElHabr) <a href="https://twitter.com/TonyElHabr/status/1530196320790642689?ref_src=twsrc%5Etfw">May 27, 2022</a>

</blockquote>

```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```
**SARCASM DE-ACTIVATED**

In a follow up post, we'll go more in depth regarding how we can leverage the match outcome probabilities to simulate season-ending points in a more rigorous fashion that done in the last section above.
