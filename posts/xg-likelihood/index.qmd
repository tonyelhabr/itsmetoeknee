---
title: Shooting Performance Likeliness
description: "Quantifying how unlikely a player's season-long shooting performance was"
date: 2024-05-04
draft: true
categories:
  - r
  - soccer
image: header.png
execute: 
  code-fold: show
  eval: false
  include: true
  echo: false
---

# Introduction

Towards the end of each soccer season, we naturally start to look back at player performances, often looking to seems to have improved the most compared to their past seasons. Or, on the other end of the spectrum, who disappointed the most. We may have different motivations for doing so--e.g. we may be trying to attribute team over- and under-performance to individuals, we may be hypothesizing who is likely to be transferred or resigned, etc.

The question "How unexpected (or "unlikely") was player X's shooting performance this season?" is often posed when observing a large difference in a player's goals scored and [expected goals (xG)](https://theanalyst.com/na/2021/07/what-are-expected-goals-xg/). For instance, if a striker only scored 8 goals in a given season on 12 xG, their "underperformance" of 4 goals is certainly notable, as its about 50% lower than expected (i.e. `(8 - 12) / 12`).

The ["Outperformance" ($O$) ratio](/posts/xg-ratio-empirical-bayes/)--the ratio of a player $p$'s (non-penalty) goals $G$ to expected goals $xG$--is perhaps the most common way of evaluating shooting performance.[^1]

[^1]: The raw difference between goals and xG is another reasonable measure of shooting performance, but it can "hide" shot volume. Is it fair to compare a player who take 100 shots in a year and scores 12 goals on 10 xG with a player who takes 10 shots and scores 3 goals on 1 xG? The raw difference is +2 in both cases, indicating no difference in the shooting performance for the two players. But $O$ would be 1.2 and 3 respectively, hinting at the former player's small sample size (since no one can reasonably expect to sustain an $O$ greater than 1.5 or 2 over many shots).

$$
O_p = \frac{G_p}{xG_p}
$$ {#eq-o}

Intuitively, an $O_p$ ratio of 1 indicates that a player is scoring as many goals as expected; a ratio greater than 1 indicates underperformance; and a ratio less than 1 indicates overperformance. Our hypothetical player underperformed with an $O$ ratio of 0.67 (i.e. $O = \frac{8}{12} = 0.75$).

In most cases, we have prior seasons of data to use when evaluating a player's $O$ ratio for a given season. For example, let's say our hypothetical player scored 12 goals on 10 xG ($O = 1.2$) in the season prior, and 11 goals on 10 xG ($O = 1.1$) before that. Putting things in perspective, an $O = 0.75$ after those performances seems even more likely, compared to an "average" player who theoretically achieves $O = 1$ ratio every year.

So how do we put a number on the unlikeliness of that $O = 0.75$ for our hypothetical player, accounting for their prior season-long performances?

### Data

For this post, I'll be using public data from [FBref](https://fbref.com/) for the 2018/19 - 2023/24 seasons of the [the Big 5 European soccer leagues](https://fbref.com/en/comps/Big5/Big-5-European-Leagues-Stats). Fake data is nice for examples, but ultimately we want to test our methods on real data. Our intuition about the results can be a useful caliber of the sensibility of our results.

```{r}
#| label: setup
#| code-fold: true
#| code-summary: "Setup"
library(dplyr)
library(purrr)
library(rlang)
library(tidyr)

library(worldfootballR)

library(qs)

COUNTRIES <- c('ENG', 'ESP', 'GER', 'ITA', 'FRA')
GENDERS <- 'M'
SEASON_END_YEARS <- 2018:2024
TIER <- '1st'
PROJ_DIR <- 'posts/xg-likelihood'
```

```{r}
#| label: reprex_print
#| include: false
reprex_print <- function(...) {
  capture.output(...) |> 
    paste('#>', x = _) |> 
    cat(sep = '\n')
}
```

```{r}
#| label: shots
#| code-fold: false
#| code-summary: "Get shot-level data"
raw_shots <- worldfootballR::load_fb_match_shooting(
  country = COUNTRIES,
  tier = TIERS,
  gender = GENDERS,
  season_end_year = SEASON_END_YEARS
)
#> → Data last updated 2024-04-25 17:52:47 UTC

np_shots <- raw_shots |> 
  ## Drop penalties
  dplyr::filter(
    !dplyr::coalesce((Distance == '13' & round(as.double(xG), 2) == 0.79), FALSE)
  ) |> 
  dplyr::transmute(
    season_end_year = Season_End_Year,
    player_id = Player_Href |> dirname() |> basename(),
    player = Player,
    match_date = lubridate::ymd(Date),
    match_id = MatchURL |> dirname() |> basename(),
    minute = Minute,
    g = as.integer(Outcome == 'Goal'),
    xg = as.double(xG)
  ) |> 
  ## A handful of scored shots with empty xG
  dplyr::filter(!is.na(xg)) |> 
  dplyr::arrange(season_end_year, player_id, match_date, minute)

## Use the more commonly used name when a player ID is mapped to multiple names
##   (This "bug" happens because worldfootballR doesn't go back and re-scrape data
##   when fbref makes a name update.)
player_name_mapping <- np_shots |> 
  dplyr::count(player_id, player) |> 
  dplyr::group_by(player_id) |> 
  dplyr::slice_max(n, n = 1, with_ties = FALSE) |> 
  dplyr::ungroup() |> 
  dplyr::distinct(player_id, player)

player_season_np_shots <- np_shots |> 
  dplyr::summarize(
    .by = c(player_id, season_end_year), 
    shots = dplyr::n(),
    dplyr::across(c(g, xg), sum)
  ) |> 
  dplyr::mutate(
    o = g / xg
  ) |> 
  dplyr::left_join(
    player_name_mapping,
    by = dplyr::join_by(player_id)
  ) |> 
  dplyr::relocate(player, .after = player_id) |> 
  dplyr::arrange(player_id, season_end_year)
player_season_np_shots
#> # A tibble: 15,317 × 7
#>    player_id player          season_end_year shots     g    xg     o
#>    <chr>     <chr>                     <int> <int> <int> <dbl> <dbl>
#>  1 0000acda  Marco Benassi              2018    70     5  4.01 1.25 
#>  2 0000acda  Marco Benassi              2019    59     7  5.61 1.25 
#>  3 0000acda  Marco Benassi              2020    20     1  1.01 0.990
#>  4 0000acda  Marco Benassi              2022    10     0  0.99 0    
#>  5 0000acda  Marco Benassi              2023    19     0  1.35 0    
#>  6 000b3da6  Manuel Iturra              2018     2     0  0.41 0    
#>  7 00242715  Moussa Niakhate            2018    16     0  1.43 0    
#>  8 00242715  Moussa Niakhate            2019    10     1  1.5  0.667
#>  9 00242715  Moussa Niakhate            2020    11     1  1.02 0.980
#> 10 00242715  Moussa Niakhate            2021     9     2  1.56 1.28 
#> # ℹ 15,307 more rows
```

```{r}
#| label: np_shots-save
#| code-fold: true
#| include: false
qs::qsave(np_shots, file.path(PROJ_DIR, 'np_shots.qs'))
qs::qsave(player_season_np_shots, file.path(PROJ_DIR, 'player_season_np_shots.qs'))
```

```{r}
#| label: np_shots-read
#| include: false
np_shots <- qs::qread(file.path(PROJ_DIR, 'np_shots.qs'))
player_season_np_shots <- qs::qread(file.path(PROJ_DIR, 'player_season_np_shots.qs'))
```

```{r}
#| label: players_to_evaluate
#| include: false
players_to_evaluate <- dplyr::inner_join(
  player_season_np_shots |> 
    dplyr::filter(season_end_year < 2024L) |>
    dplyr::summarize(
      .by = c(player_id, player),
      prior_count = n(), 
      prior_count_with_pos_o = sum(o > 1),
      prior_count_with_neg_o = sum(o < 1),
      dplyr::across(
        c(
          shots,
          g,
          xg,
        ),
        \(.x) sum(.x),
        .names = 'prior_{.col}'
      )
    ) |>
    dplyr::arrange(dplyr::desc(prior_shots)),
  player_season_np_shots |> 
    dplyr::filter(season_end_year == 2024L) |> 
    dplyr::select(
      player_id,
      shots,
      g,
      xg,
      o
    ) |> 
    dplyr::rename_with(
      \(.x) paste0('target_', .x),
      c('shots', 'g', 'xg', 'o')
    ),
  by = dplyr::join_by(player_id)
)

players_to_evaluate |> 
  dplyr::filter(prior_count == prior_count_with_pos_o, target_o < 1) |> 
  dplyr::arrange(dplyr::desc(prior_shots))

players_to_evaluate |> 
  dplyr::filter(prior_count == prior_count_with_neg_o, target_o > 1) |> 
  dplyr::arrange(dplyr::desc(prior_shots))
```

We'll focus on one player in particular--[James Maddison](https://fbref.com/en/players/ee38d9c5/James-Maddison) and [Matheus Cunha](https://fbref.com/en/players/dc62b55d/Matheus-Cunha). Maddison has had a sub-par 2023/2024 season for his own standards, underperforming his xG for the first time in since he started playing in the Premier League in 2018/19. On the other hand, Cunha--who has bounced around teams across the Bundesliga, La Liga, and most recently the Premier League--has overperformed his xG for the first time this season.

```{r}
#| label: select_np_season_shooting
#| code-fold: false
SELECT_PLAYERS <- c(
  'ee38d9c5' = 'James Maddison',
  'dc62b55d' = 'Matheus Cunha'
)
select_np_season_shooting <- player_season_np_shots |>
  dplyr::filter(player_id %in% names(SELECT_PLAYERS))
select_np_season_shooting
#> # A tibble: 12 × 7
#>    player_id player         season_end_year shots     g    xg     o
#>    <chr>     <chr>                    <int> <int> <int> <dbl> <dbl>
#>  1 dc62b55d  Matheus Cunha             2019    34     2  4.16 0.481
#>  2 dc62b55d  Matheus Cunha             2020    51     5  5.34 0.936
#>  3 dc62b55d  Matheus Cunha             2021    68     5  6.91 0.724
#>  4 dc62b55d  Matheus Cunha             2022    39     6  6.06 0.990
#>  5 dc62b55d  Matheus Cunha             2023    38     2  3.44 0.581
#>  6 dc62b55d  Matheus Cunha             2024    71    10  8.59 1.16 
#>  7 ee38d9c5  James Maddison            2019    81     6  5.85 1.03 
#>  8 ee38d9c5  James Maddison            2020    74     6  5.36 1.12 
#>  9 ee38d9c5  James Maddison            2021    75     8  3.86 2.07 
#> 10 ee38d9c5  James Maddison            2022    72    12  7.56 1.59 
#> 11 ee38d9c5  James Maddison            2023    83     9  7.12 1.26 
#> 12 ee38d9c5  James Maddison            2024    49     4  4.72 0.847
```

## Analysis

### Approach 0: $t$-test

If you have some background in statistics, perhaps the first approach that comes to mind is a [$t$-test](https://en.wikipedia.org/wiki/Student%27s_t-test) (using shot-weighted averages and standard deviations).

```{r}
#| label: select_np_season_shooting-t-test
#| code-fold: false
#| code-summary: "Performing a t-test for likelihood of Maddison's 2024 outperformance"
TARGET_SEASON_END_YEAR <- 2024

select_np_season_shooting |> 
  dplyr::filter(season_end_year < TARGET_SEASON_END_YEAR) |> 
  dplyr::summarise(
    .by = c(player_id, player),
    mean = weighted.mean(o, w = shots),
    ## could also use a function like Hmisc::wtd.var for weighted variance
    sd = sqrt(sum(shots * (o - weighted.mean(o, w = shots))^2) / sum(shots))
  ) |> 
  dplyr::inner_join(
    select_np_season_shooting |> 
      dplyr::filter(season_end_year == TARGET_SEASON_END_YEAR) |> 
      dplyr::select(player_id, target_o = o),
    by = dplyr::join_by(player_id)
  ) |> 
  dplyr::mutate(
    z_score = (target_o - mean) / sd,
    p_value = 2 * pnorm(-abs(z_score))
  ) |> 
  dplyr::arrange(player)
#> # A tibble: 2 × 7
#>   player_id player          mean    sd target_o z_score p_value
#>   <chr>     <chr>          <dbl> <dbl>    <dbl>   <dbl>   <dbl>
#> 1 ee38d9c5  James Maddison 1.40  0.378    0.847   -1.47  0.141 
#> 2 dc62b55d  Matheus Cunha  0.757 0.182    1.16     2.24  0.0250
```

In reality, this isn't giving us a percentage of likelihood of the outcome. Rather, the p-value measures the probability of obtaining an outperformance as extreme as the one observed in 2023/24 (or more extreme) if the null hypothesis is true. The null hypothesis in this case would be that there is no significant difference between the player's actual outperformance ratio in the 2023/24 season and the distribution of outperformance ratios observed in previous seasons.

The t-test indicates that Cunha's goals-to-xG ratio this year violates the null hypothesis, suggesting that this season has been significantly remarkable for him. On the other hand, the t-test indicates that there is **not** sufficient evidence that Maddison's $O$ this season is significantly worse than his $O$ in prior seasons.

### Approach 1: Sampling from Prior History of Shots

We're not going to get very far just using a "traditional" approach, nor just by looking at the player-season level. We need to dive into shot-level data to more robustly understand uncertainty.

A fairly simple approach to quantifying unlikeness (that may be just "good enough") is this:

1.  **Sample** $N_p$ shots from a player's past shots in $M$ simulations. (Change nothing about the shot's xG and goal outcomes.) $N_p$ should be set equal to the number of shots a player has taken in the target season, i.e. 2023/24 here. $M$ should be set to some fairly large number, so as to achieve stability in the results.
2.  To quantify unlikeliness of an underperforming season (relative to a given player's past seasons), **count up in how many simulations** $m^+$ the outperformance ratio $O$ of the resampled shots is lower than the observed $O_{p, \text{target}}$ ratio in the target season for the player.[^2] The proportion $U^- = \frac{m^-}{M}$ represents the unlikeness of a given player's observed $O$ in the target season.

[^2]: Similarly, to estimate the unlikeness of an overperforming season, count up in how many simulations $m^-$ the outperformance ratio of the resampled shots is greater than $O_{p,\text{target}}$ and calculate the proportion $U^+ = \frac{m^+}{M}$.

Here's how that looks in code.

```{r}
#| label: select_resampled_props
#| code-fold: false
#| code-summary: "Approach 1"
## To have a variable to reference for player-level target and aggregate prior stats
player_np_shots <- player_season_np_shots |> 
  dplyr::mutate(
    is_target = season_end_year == TARGET_SEASON_END_YEAR
  ) |> 
  dplyr::summarize(
    .by = c(is_target, player_id, player),
    dplyr::across(
      c(shots, g, xg),
      \(.x) sum(.x, na.rm = TRUE)
    )
  ) |> 
  dplyr::mutate(o = g / xg) |> 
  dplyr::arrange(player, player_id, is_target)

wide_player_np_shots <- player_np_shots |>
  dplyr::transmute(
    player_id, 
    player,
    which = ifelse(is_target, 'target', 'prior'), 
    shots, g, xg, o
  ) |> 
  tidyr::pivot_wider(
    names_from = which, 
    values_from = c(shots, g, xg, o), 
    names_glue = '{which}_{.value}'
  )

resample_player_shots <- function(
    shots, 
    n_shots_to_sample, 
    n_sims = 1000,
    replace = TRUE,
    seed = 42
) {
  
  withr::local_seed(seed)
  purrr::map_dfr(
    1:n_sims,
    \(.sim) {
      sampled_shots <- shots |> 
        slice_sample(n = n_shots_to_sample, replace = replace)
      
      list(
        sim = .sim,
        xg = sum(sampled_shots$xg),
        g = sum(sampled_shots$g),
        o = sum(sampled_shots$g) / sum(sampled_shots$xg)
      )
    }
  )
}

resample_player_o <- function(shots, players, target_season_end_year) {
  purrr::imap_dfr(
    players,
    \(.player, .player_id) {
      player_shots <- shots |> 
        dplyr::filter(player_id == .player_id)
      
      target_shots <- player_shots |>
        dplyr::filter(season_end_year == target_season_end_year)
      
      player_shots |>
        dplyr::filter(season_end_year < target_season_end_year) |> 
        resample_player_shots(
          n_shots_to_sample = nrow(target_shots)
        ) |> 
        dplyr::mutate(
          player_id = .player_id,
          player = .player
        )
    }
  )
}

select_resampled_o <- np_shots |> 
  resample_player_o(
    players = SELECT_PLAYERS,
    target_season_end_year = TARGET_SEASON_END_YEAR
  ) |> 
  dplyr::inner_join(
    wide_player_np_shots |> 
      dplyr::select(
        player_id,
        prior_o,
        target_o
      ),
    by = dplyr::join_by(player_id)
  ) |> 
  dplyr::arrange(player, player_id)

select_resampled_props <- select_resampled_o |>
  dplyr::summarize(
    .by = c(player_id, player, prior_o, target_o),
    prop_lte = sum(o <= target_o) / n()
  ) |> 
  dplyr::arrange(player)
select_resampled_props
#> # A tibble: 2 × 5
#>   player_id player         prior_o target_o prop_lte
#>   <chr>     <chr>            <dbl>    <dbl>    <dbl>
#> 1 ee38d9c5  James Maddison   1.38     0.847    0.163
#> 2 dc62b55d  Matheus Cunha    0.772    1.16     0.898
```

These results imply that Maddison's 2023/24 outperformance ratio of 0.847 (or worse) occurs in 16.3% of simulations (`prop_lte`), and that Cunha's 2023/24 $O$ ratio of 1.16 (or better) occurs in 10.3% of simulations (`1 - prop_lte`). Honestly those numbers feel fairly reasonable.

This approach is fairly simplistic and elegant--we just sample shots from a player's history and count up the outcomes with respect to a target threshold.

```{r}
#| label: plot-maddison-sims
#| code-fold: true
#| code-summary: "Plotting Maddison's resamples shots"
library(ggplot2)
library(sysfonts)
library(showtext)
library(ggtext)
library(htmltools)

TAG_LABEL <- htmltools::tagList(
  htmltools::tags$span(htmltools::HTML(enc2utf8("&#xf099;")), style = 'font-family:fb'),
  htmltools::tags$span("@TonyElHabr"),
)
CAPTION_LABEL <- '**Data**: Opta via fbref. Updated through 2024-04-26.'
# SUBTITLE_LABEL <- 'Big 5 Leagues, 2017/18 - 2022/23'
PLOT_RESOLUTION <- 300
WHITISH_FOREGROUND_COLOR <- 'white'
COMPLEMENTARY_FOREGROUND_COLOR <- '#cbcbcb' # '#f1f1f1'
BLACKISH_BACKGROUND_COLOR <- '#1c1c1c'
COMPLEMENTARY_BACKGROUND_COLOR <- '#4d4d4d'
FONT <- 'Titillium Web'
sysfonts::font_add_google(FONT, FONT)
## https://github.com/tashapiro/tanya-data-viz/blob/main/chatgpt-lensa/chatgpt-lensa.R for twitter logo
sysfonts::font_add('fb', 'Font Awesome 6 Brands-Regular-400.otf')
showtext::showtext_auto()
showtext::showtext_opts(dpi = PLOT_RESOLUTION)

ggplot2::theme_set(ggplot2::theme_minimal())
ggplot2::theme_update(
  text = ggplot2::element_text(family = FONT),
  title = ggplot2::element_text(size = 18, color = WHITISH_FOREGROUND_COLOR),
  plot.title = ggtext::element_markdown(face = 'bold', size = 18, color = WHITISH_FOREGROUND_COLOR),
  plot.title.position = 'plot',
  plot.subtitle = ggtext::element_markdown(size = 18, color = COMPLEMENTARY_FOREGROUND_COLOR),
  axis.text = ggplot2::element_text(color = WHITISH_FOREGROUND_COLOR, size = 14),
  # axis.title = ggplot2::element_text(size = 14, color = WHITISH_FOREGROUND_COLOR, face = 'bold', hjust = 0.99),
  axis.title.x = ggtext::element_markdown(size = 14, color = WHITISH_FOREGROUND_COLOR, face = 'bold', hjust = 0.99),
  axis.title.y = ggtext::element_markdown(size = 14, color = WHITISH_FOREGROUND_COLOR, face = 'bold', hjust = 0.99),
  axis.line = ggplot2::element_blank(),
  strip.text = ggplot2::element_text(size = 14, color = WHITISH_FOREGROUND_COLOR, face = 'bold', hjust = 0),
  panel.grid.major = ggplot2::element_line(color = COMPLEMENTARY_BACKGROUND_COLOR),
  panel.grid.minor = ggplot2::element_line(color = COMPLEMENTARY_BACKGROUND_COLOR),
  panel.grid.minor.x = ggplot2::element_blank(),
  panel.grid.minor.y = ggplot2::element_blank(),
  plot.margin = ggplot2::margin(10, 20, 10, 20),
  plot.background = ggplot2::element_rect(fill = BLACKISH_BACKGROUND_COLOR, color = BLACKISH_BACKGROUND_COLOR),
  plot.caption = ggtext::element_markdown(color = WHITISH_FOREGROUND_COLOR, hjust = 0, size = 10, face = 'plain'),
  plot.caption.position = 'plot',
  plot.tag = ggtext::element_markdown(size = 10, color = WHITISH_FOREGROUND_COLOR, hjust = 1),
  plot.tag.position = c(0.99, 0.01),
  panel.spacing.x = grid::unit(2, 'lines'),
  panel.background = ggplot2::element_rect(fill = BLACKISH_BACKGROUND_COLOR, color = BLACKISH_BACKGROUND_COLOR)
)

group_palette <- c(
  'gte' = '#00bbf9',
  'other' = '#6E7275',
  'lte' = '#f15bb5'
)

maddison_resampled_o <- select_resampled_o |>
  dplyr::filter(player == 'James Maddison') |> 
  dplyr::mutate(
    group = ifelse(o <= target_o, 'lte', 'other')
  )

maddison_resampled_o_plot <- maddison_resampled_o |> 
  ggplot2::ggplot() +
  ggplot2::aes(
    x = o
  ) +
  ggplot2::geom_histogram(
    ggplot2::aes(fill = group),
    binwidth = 0.05,
    show.legend = FALSE
  ) +
  ggplot2::scale_fill_manual(
    values = group_palette
  ) +
  ggplot2::geom_vline(
    ggplot2::aes(xintercept = 1),
    color = 'white',
    linetype = 1,
    linewidth = 1.5
  ) +
  ggplot2::coord_cartesian(
    ylim = c(0, 48), 
    xlim = c(0, 4),
    expand = FALSE,
    clip = 'off'
  ) +
  ggplot2::annotate(
    geom = 'text',
    x = 0.95,
    y = 45,
    hjust = 1,
    label = 'Underperformance',
    color = WHITISH_FOREGROUND_COLOR,
    fontface = 'bold',
    family = FONT,
    size = 12 / .pt
  ) +
  ggplot2::annotate(
    geom = 'text',
    x = 1.05,
    y = 45,
    hjust = 0,
    label = 'Overperformance',
    color = WHITISH_FOREGROUND_COLOR,
    fontface = 'bold',
    family = FONT,
    size = 12 / .pt
  ) +
  ggplot2::annotate(
    geom = 'text',
    x = 2.5,
    y = 45,
    hjust = 0,
    vjust = 1,
    label = "An outperformance ratio of 0.847\n(Maddison's 2023/24 G / xG ratio)\nor worse occurs in only\n0.43% of 10k simulations",
    color = group_palette[['lte']],
    fontface = 'italic',
    family = FONT,
    size = 11 / .pt
  ) +
  ggplot2::annotate(
    geom = 'curve',
    x = 2.4,
    y = 40,
    xend = 0.8,
    yend = 26,
    arrow = grid::arrow(length = grid::unit(3, 'pt'), type = 'closed'),
    linewidth = 0.5,
    curvature = 0.25,
    color = group_palette[['lte']]
  )  +
  ggplot2::annotate(
    ggpath::GeomFromPath,
    x = 4,
    y = 55,
    path = file.path(PROJ_DIR, '493165.png'),
    width = 0.08
  ) +
  ggplot2::theme(
    plot.title = ggtext::element_markdown(size = 16),
    plot.subtitle = ggtext::element_markdown(size = 12)
  ) +
  ggplot2::labs(
    title = 'Resampled Shooting Outperformance Ratio (G / xG) for James Maddison',
    subtitle = "Shots Sampled From Maddison's 2018/19 - 2022/2023 Seasons",
    x = 'Outperformance Ratio (G / xG)',
    y = 'Count of Simulations',
    caption = CAPTION_LABEL,
    tag = TAG_LABEL
  )

ggplot2::ggsave(
  maddison_resampled_o_plot,
  filename = file.path(PROJ_DIR, 'maddison-resampled-samples.png'),
  width = 8,
  height = 8 / 1.5
)
```

So is this good enough? Maybe. There are some caveats I can think of:

1.  We're implicitly making an assumption that a player's past shot profile is representative of their future shot profile.
2.  We're effectively treating each player's G / xG ratio as constant and only trying to understand the uncertainty around it.

These things don't necessarily mean that this methodology is bad--it just has its caveats.

#### Aside

Oh, and you can get odd outcomes. For example, looking at Haaland's numbers from 2023/24, this procedure finds his outcome to be extremely unlikely. We know that it like is, but just a 0.4% outcome seems like an understimate.

```{r}
#| label: all-resamples
#| code-fold: true
#| code-summary: "Approach 1, but with all players (meeting some baseline criteria)"
all_players_to_resample <- wide_player_np_shots |> 
  tidyr::drop_na(prior_o, target_o) |> 
  dplyr::filter(
    prior_shots >= 50,
    target_shots >= 10,
    prior_g > 0, 
    target_g > 0
  ) |> 
  dplyr::select(
    player_id,
    player,
    prior_o,
    target_o
  )

all_resampled_shots <- purrr::imap_dfr(
  rlang::set_names(
    all_players_to_resample$player,
    all_players_to_resample$player_id,
  ),
  \(.player, .player_id) {
    message(sprintf('Resampling for %s', .player))
    player_shots <- np_shots |> 
      dplyr::filter(player_id == .player_id)
    
    target_shots <- player_shots |>
      dplyr::filter(season_end_year == TARGET_SEASON_END_YEAR)
    
    player_shots |>
      dplyr::filter(season_end_year < TARGET_SEASON_END_YEAR) |> 
      resample_player_shots(
        n_shots_to_sample = nrow(target_shots)
      ) |> 
      dplyr::mutate(
        player_id = .player_id,
        player = .player
      )
  }
) |> 
  dplyr::inner_join(
    wide_player_o |> 
      dplyr::select(
        player_id,
        prior_o,
        target_o,
        prior_shots,
        target_shots
      ),
    by = dplyr::join_by(player_id)
  ) |> 
  dplyr::arrange(player, player_id)

all_resampled_props <- all_resampled_shots |>
  dplyr::summarize(
    .by = c(player, prior_o, target_o, prior_shots, target_shots),
    prop_lte = sum(o <= target_o) / n()
  ) |> 
  dplyr::arrange(prop_lte)
all_resampled_props
#> # A tibble: 593 × 6
#>    player              prior_o target_o prior_shots target_shots prop_lte
#>    <chr>                 <dbl>    <dbl>       <int>        <int>    <dbl>
#>  1 Erling Haaland         1.26    0.791         313           98    0.004
#>  2 Amine Harit            1.27    0.262         107           33    0.01 
#>  3 Pierre-Emerick Aub…    1.07    0.606         405           91    0.01 
#>  4 Téji Savanier          1.42    0.282         276           72    0.01 
#>  5 Antonio Sanabria       1.05    0.386         269           47    0.014
#>  6 Alex Baena             1.54    0.348          61           57    0.016
#>  7 Elye Wahi              1.38    0.753         114           47    0.017
#>  8 Kevin Behrens          1.39    0.673          51           52    0.019
#>  9 Ciro Immobile          1.23    0.383         635           41    0.02 
#> 10 Ansu Fati              1.31    0.430         125           34    0.024
#> # ℹ 583 more rows
#> # ℹ Use `print(n = ...)` to see more rows
```

```{r}
#| label: all_resampled_shots-save
#| include: false
qs::qsave(all_resampled_shots, file.path(PROJ_DIR, 'all_resampled_shots.qs'))
```

```{r}
#| label: all_resampled_shots-read
#| include: false
all_resampled_shots <- qs::qread(file.path(PROJ_DIR, 'all_resampled_shots.qs'))
```

### Approach 2: Sampling from the Posterior of an Empirical Bayes Shrunken Estimate

Borrowing from [my own prior art](/posts/xg-empirical-bayes), we can apply an [Empirical Bayes](https://en.wikipedia.org/wiki/Empirical_Bayes_method) (EB) procedure to create a less noisy estimate what each player's outperformance ratio $O$ might be in the long run.[^3] Shrinking a given player's observed $O$ ratio effectively addresses one of the shortcomings of approach 2, where we implicitly treated a player's historical G / xG ratio as static truth.

[^3]: Typically we'd summarize the posterior distribution in EB estimation with the mean, e.g. "Maddison's observed outperformance ratio through 2022/23 is 1.21, and his shrunken EB estimate (mean of the posterior) is 1.13". But we can do more with the posterior distribution.

For estimating the unlikeliness of observed 2023/24 outcomes, we do as follows:

1.  Apply EB shrinkage to a player's outperformance ratio $O_p$, excluding the target season.
2.  Determine unlikeness in the same manner as step 2 from approach 2, i.e. We count up the number of posterior samples in which the sampled $\hat{O}_p$ is less than the player's observed $O_p$ in the target season.

The code that follows shares similarities to [my prior code](/posts/xg-empirical-bayes), but notably we estimate prior distribution parameter values for each player separately.

```{r}
#| label: eb-posterior-sampling
#| code-fold: true
#| code-summary: "Approach 2"
## Similar to my code in /posts/xg-empirical-bayes
N_SIMS <- 10000

## We need to choose "bounds" sometimes to help MASS::fidistr estimate parameter values.
##   In practice, I found that MASS::fidistr + dgamma needed a vector of length 5
##   before `lower` and `upper` need not be specified. But we can't gaurantee that we'll
##   always have a vector of at least 5 values to pass to it, so we must guide it
##   by intelligently choosing lower and upper bounds.
## At 500 shots, we feel like we can set pretty strong lower and upper bounds
##   for the prior parameters to estimate. Around 50 shots is when we feel like we can
##   start moving up our bounds from (1, 1)
choose_prior_bound <- function(x, to, from = c(50, 500)) {
  dplyr::case_when(
    x < from[1] ~ to[1],
    x >= from[2] ~ to[2],
    TRUE ~ scales::rescale(x, from = from, to = to)
  )
}

choose_prior_lower_bound <- function(x) {
  choose_prior_bound(
    x = x,
    to = c(1, 25)
  )
}

choose_prior_upper_bound <- function(x) {
  choose_prior_bound(
    x = x,
    to = c(10, 50)
  )
}

## By default:
## 1. `lower`: Don't return values less than 1 (too weak of a prior)
## 2. `upper`: Dont' return values greater than 25 (too strong of a prior)
estimate_prior_distr_params <- function(x, lower = 1, upper = 25) {
  prior_distr <- MASS::fitdistr(
    x + 1e-6, ## fudge factor to prevent 0s,
    dgamma,
    start = list(shape = 1, rate = 1),
    lower = lower,
    upper = upper
  )
  
  list(
    shape = unname(prior_distr$estimate[1]),
    rate = unname(prior_distr$estimate[2])
  )
}

simulate_gamma_posterior <- function(
    successes, 
    trials, 
    prior_shape, 
    prior_rate, 
    n_sims = N_SIMS,
    seed = 42
) {
  posterior_shape <- prior_shape + successes
  posterior_rate <- prior_rate + trials
  withr::local_seed(seed)
  posterior_sample <- rgamma(
    n = n_sims, 
    shape = posterior_shape, 
    rate = posterior_rate
  )
  list(
    'params' = list(
      'shape' = posterior_shape,
      'rate' = posterior_rate
    ),
    'samples' = posterior_sample,
    'mean' = mean(posterior_sample)
  )
}

unnest_posterior <- function(df) {
  df |> 
    dplyr::select(
      player_id, player,
      prior_shots = shots, prior_g = g, prior_xg = xg, prior_o = o, adj_o
    ) |> 
    tidyr::unnest_wider(
      adj_o, 
      names_sep = '_'
    ) |> 
    dplyr::arrange(desc(adj_o_mean))
}

select_posterior_o <- purrr::imap_dfr(
  SELECT_PLAYERS,
  \(.player, .player_id) {
    
    player_np_shots <- np_shots |> 
      dplyr::filter(player_id == .player_id) |> 
      dplyr::mutate(is_target = season_end_year == TARGET_SEASON_END_YEAR)
    
    prior_player_np_shots <- player_np_shots |> 
      dplyr::filter(!is_target)
    
    target_player_np_shots <- player_np_shots |> 
      dplyr::filter(is_target)
    
    n_prior_shots <- nrow(prior_player_np_shots)
    n_target_shots <- nrow(target_player_np_shots)
    
    n_folds <- (n_prior_shots %/% n_target_shots) + 1L
    shots_in_each_fold <- n_prior_shots %/% n_folds
    
    ## For the purpose of estimating a prior, split the player's prior shot history into
    ##   equally sized intervals (`fold`) that are approximately equal to (but usually
    ##   smaller than) their target season shot volume.
    numbered_player_np_shots <- prior_player_np_shots |> 
      dplyr::arrange(match_date, minute) |> 
      dplyr::mutate(
        rn = dplyr::row_number(),
        fold = 1L + ((rn - 1L) %/% shots_in_each_fold),
        ## add any leftover to the last fold
        fold = ifelse(fold > n_folds, n_folds, fold)
      )
    
    prior_distr_shots <- numbered_player_np_shots |> 
      dplyr::summarize(
        .by = c(fold),
        shots = dplyr::n(),
        dplyr::across(c(g, xg), \(.x) sum(.x))
      ) |> 
      dplyr::mutate(o = g / xg)
    
    agg_player_np_shots <- player_np_shots |>
      dplyr::summarize(
        .by = c(is_target),
        shots = dplyr::n(),
        dplyr::across(c(g, xg), \(.x) sum(.x))
      ) |> 
      dplyr::mutate(o = g / xg)
    
    agg_prior_player_np_shots <- agg_player_np_shots |> 
      dplyr::filter(!is_target)
    
    agg_target_player_np_shots <- agg_player_np_shots |> 
      dplyr::filter(is_target)
    
    prior_params <- estimate_prior_distr_params(
      prior_distr_shots$o,
      lower = choose_prior_lower_bound(agg_prior_player_np_shots$shots),
      upper = choose_prior_upper_bound(agg_prior_player_np_shots$shots)
    )
    
    posterior <- simulate_gamma_posterior(
      successes = agg_target_player_np_shots$g,
      trials = agg_target_player_np_shots$xg,
      prior_shape = prior_params$shape,
      prior_rate = prior_params$rate
    )
    
    prior_prop_lte <- pgamma(
      agg_target_player_np_shots$o, 
      shape = prior_params$shape, 
      rate = prior_params$rate,
      lower.tail = TRUE
    )
    
    ## Could also do this for the posterior
    # posterior_prop_lte <- pgamma(
    #   agg_target_player_np_shots$o, 
    #   shape = posterior$params$shape, 
    #   rate = posterior$params$rate,
    #   lower.tail = TRUE
    # )
    
    posterior_prop_lte <- (
      sum(posterior$samples < agg_target_player_np_shots$o) / 
        length(posterior$samples)
    )
    
    list(
      'player_id' = .player_id,
      'player' = .player,
      'prior' = list('params' = prior_params),
      'posterior' = list(posterior),
      'prior_shots' = agg_prior_player_np_shots$shots,
      'prior_g' = agg_prior_player_np_shots$g,
      'prior_xg' = agg_prior_player_np_shots$xg,
      'prior_o' = agg_prior_player_np_shots$o,
      'target_shots' = n_target_shots,
      'target_g' = agg_target_player_np_shots$g,
      'target_xg' = agg_target_player_np_shots$xg,
      'target_o' = agg_target_player_np_shots$o,
      'prior_prop_lte' = prior_prop_lte,
      'posterior_prop_lte' = posterior_prop_lte
    )
  }
)

select_posterior_o |> 
  dplyr::select(player, target_o, prior_prop_lte, posterior_prop_lte)
#> # A tibble: 2 × 4
#>   player         target_o prior_prop_lte posterior_prop_lte
#>   <chr>             <dbl>          <dbl>              <dbl>
#> 1 James Maddison    0.847         0.0456              0.064
#> 2 Matheus Cunha     1.16          0.891               0.823
```

We see that Maddison's 2023/24 $O$ value of 0.847 (or worse) was about 26.6% unlikely given his prior shot history (`prior_prop_lte`). After observing his 2023/24 shooting performance, we can "update" that belief and say that the unlikeness of Maddison achieving such a G/xG ratio (or worse) again would be 35.9% (`posterior_prop_lte`).

Using the same line of reasoning, we can say that Cunha's 2023/24 $O$ ratio of 1.16 was an 4.63% percentile outcome (`1 - prior_prop_lte`). After this season, we might expect Cunha to repeat the outcome in just 1 out of 10 seasons (`1 - posterior_prop_lte`).

To gain some intuition around this approach, we can plot out the posterior samples for Maddison just as we did before.

```{r}
maddison_posterior_o <- select_posterior_o |>
  dplyr::filter(player == 'James Maddison') |> 
  dplyr::select(
    posterior,
    target_o
  ) |> 
  tidyr::unnest_wider(posterior) |> 
  dplyr::select(o = samples, target_o) |>
  tidyr::unnest_longer(o) |> 
  dplyr::mutate(
    group = ifelse(o <= target_o, 'lte', 'other')
  )

maddison_posterior_o_plot <- maddison_posterior_o |> 
  ggplot2::ggplot() +
  ggplot2::aes(
    x = o
  ) +
  ggplot2::geom_vline(
    data = dplyr::distinct(maddison_posterior_o, target_o),
    ggplot2::aes(xintercept = target_o),
    linetype = 2,
    color = 'white'
  ) +
  ggplot2::geom_histogram(
    ggplot2::aes(fill = group),
    binwidth = 0.05,
    show.legend = FALSE
  ) +
  ggplot2::scale_fill_manual(
    values = group_palette
  ) +
  ggplot2::geom_vline(
    ggplot2::aes(xintercept = 1),
    color = 'white',
    linetype = 1,
    linewidth = 1.5
  ) +
  ggplot2::coord_cartesian(
    ylim = c(-50, 1050), 
    xlim = c(-0.05, 2.55),
    expand = FALSE,
    clip = 'off'
  ) +
  ggplot2::annotate(
    geom = 'text',
    x = 0.95,
    y = 950,
    hjust = 1,
    label = 'Underperformance',
    color = WHITISH_FOREGROUND_COLOR,
    fontface = 'bold',
    family = FONT,
    size = 12 / .pt
  ) +
  ggplot2::annotate(
    geom = 'text',
    x = 1.05,
    y = 950,
    hjust = 0,
    label = 'Overperformance',
    color = WHITISH_FOREGROUND_COLOR,
    fontface = 'bold',
    family = FONT,
    size = 12 / .pt
  ) +
  ggplot2::annotate(
    geom = 'text',
    x = 1.6,
    y = 850,
    hjust = 0,
    vjust = 1,
    label = "An outperformance ratio of 0.847\n(Maddison's 2023/24 G / xG ratio)\nor worse occurs in 6.2% of 10k\nsimulations",
    color = group_palette[['lte']],
    fontface = 'italic',
    family = FONT,
    size = 11 / .pt
  ) +
  ggplot2::annotate(
    geom = 'curve',
    x = 1.55,
    y = 800,
    xend = 0.85,
    yend = 400,
    arrow = grid::arrow(length = grid::unit(3, 'pt'), type = 'closed'),
    linewidth = 0.5,
    curvature = 0.25,
    color = group_palette[['lte']]
  )  +
  ggplot2::annotate(
    ggpath::GeomFromPath,
    x = 2.5,
    y = 1100,
    path = file.path(PROJ_DIR, '493165.png'),
    width = 0.08
  ) +
  ggplot2::theme(
    plot.title = ggtext::element_markdown(size = 16),
    plot.subtitle = ggtext::element_markdown(size = 12)
  ) +
  ggplot2::labs(
    title = 'Posterior Distribution of G / xG Ratio for James Maddison',
    subtitle = "Prior based on Maddison's 2018/19 - 2022/2023 seasons. Update based on his 2023/24 season.",
    x = 'Outperformance Ratio (G / xG)',
    y = 'Count of Simulations',
    caption = CAPTION_LABEL,
    tag = TAG_LABEL
  )

ggplot2::ggsave(
  maddison_posterior_o_plot,
  filename = file.path(PROJ_DIR, 'maddison-posterior-samples.png'),
  width = 8,
  height = 8 / 1.5
)
```

#### Aside

```{r}
#| label: all_posterior_props
#| code-fold: true
#| code-summary: "Approach 2 for all players"
all_posterior_o <- purrr::imap_dfr(
  rlang::set_names(
    all_players_to_resample$player,
    all_players_to_resample$player_id
  ),
  \(.player, .player_id) {
    # idx <- 68
    # all_players_to_resample$player_id[idx] -> .player_id
    # all_players_to_resample$player[idx] -> .player
    message(sprintf('%s', .player))
    player_np_shots <- np_shots |> 
      dplyr::filter(player_id == .player_id) |> 
      dplyr::mutate(is_target = season_end_year == TARGET_SEASON_END_YEAR)
    
    prior_player_np_shots <- player_np_shots |> 
      dplyr::filter(!is_target)
    
    target_player_np_shots <- player_np_shots |> 
      dplyr::filter(is_target)
    
    n_prior_shots <- nrow(prior_player_np_shots)
    n_target_shots <- nrow(target_player_np_shots)
    
    n_folds <- (n_prior_shots %/% n_target_shots) + 1L
    shots_in_each_fold <- n_prior_shots %/% n_folds
    
    ## For the purpose of estimating a prior, split the player's prior shot history into
    ##   equally sized intervals (`fold`) that are approximately equal to (but usually
    ##   smaller than) their target season shot volume.
    numbered_player_np_shots <- prior_player_np_shots |> 
      dplyr::arrange(match_date, minute) |> 
      dplyr::mutate(
        rn = dplyr::row_number(),
        fold = 1L + ((rn - 1L) %/% shots_in_each_fold),
        ## add any leftover to the last fold
        fold = ifelse(fold > n_folds, n_folds, fold)
      )
    
    prior_distr_shots <- numbered_player_np_shots |> 
      dplyr::summarize(
        .by = c(fold),
        shots = dplyr::n(),
        dplyr::across(c(g, xg), \(.x) sum(.x))
      ) |>  
      dplyr::mutate(o = g / xg)
    
    agg_player_np_shots <- player_np_shots |>
      dplyr::summarize(
        .by = c(is_target),
        shots = dplyr::n(),
        dplyr::across(c(g, xg), \(.x) sum(.x))
      ) |> 
      dplyr::mutate(o = g / xg)
    
    agg_prior_player_np_shots <- agg_player_np_shots |> 
      dplyr::filter(!is_target)
    
    agg_target_player_np_shots <- agg_player_np_shots |> 
      dplyr::filter(is_target)
    
    prior_params <- estimate_prior_distr_params(
      c(prior_distr_shots$o),
      lower = 1, # choose_prior_lower_bound(agg_prior_player_np_shots$shots),
      upper = choose_prior_upper_bound(agg_prior_player_np_shots$shots)
    )
    
    posterior <- simulate_gamma_posterior(
      successes = agg_target_player_np_shots$g,
      trials = agg_target_player_np_shots$xg,
      prior_shape = prior_params$shape,
      prior_rate = prior_params$rate
    )
    
    prior_prop_lte <- pgamma(
      agg_target_player_np_shots$o, 
      shape = prior_params$shape, 
      rate = prior_params$rate,
      lower.tail = TRUE
    )
    
    posterior_prop_lte <- (
      sum(posterior$samples < agg_target_player_np_shots$o) / 
        length(posterior$samples)
    )
    
    list(
      'player_id' = .player_id,
      'player' = .player,
      'prior' = list('params' = prior_params),
      'posterior' = list(posterior),
      'prior_shots' = agg_prior_player_np_shots$shots,
      'prior_g' = agg_prior_player_np_shots$g,
      'prior_xg' = agg_prior_player_np_shots$xg,
      'prior_o' = agg_prior_player_np_shots$o,
      'target_shots' = n_target_shots,
      'target_g' = agg_target_player_np_shots$g,
      'target_xg' = agg_target_player_np_shots$xg,
      'target_o' = agg_target_player_np_shots$o,
      'prior_prop_lte' = prior_prop_lte,
      'posterior_prop_lte' = posterior_prop_lte
    )
  }
)
```

# Conclusion

Once upon a time I wrote about [quantifying the relative strength of top tier domestic soccer leagues](posts/soccer-league-strength). The main motivation for this was to have a general framework with which to forecast the performance drop off (or improvement) of a player when transferring from one major league to another, i.e. to answer "How many more or less goals might we expect from player X when they transfer from league A to league B?". Notably, Erling Haaland's transfer from the Bundesliga to the English Premier League vehemently defied the figures I found there, which showed around a 17% drop off.
