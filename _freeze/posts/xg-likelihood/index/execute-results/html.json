{
  "hash": "179a6a7aa75fc589b2678f94acc8de4a",
  "result": {
    "markdown": "---\ntitle: Estimating Shooting Performance Unlikeliness\ndescription: \"Quantifying how unlikely a player's season-long shooting performance is, factoring in their prior shot history\"\ndate: 2024-05-05\ndate-modified: 2024-06-09\ntoc-depth: 4\ntoc-expand: true\ncategories:\n  - r\n  - soccer\nimage: maddison_prp_approach3.png\nexecute: \n  code-fold: show\n  eval: false\n  include: false\n  echo: true\n---\n\n\n# Introduction\n\nTowards the end of each soccer season, we naturally start to look back at player stats, often looking to see who has performed worse compared to their past seasons. We may have different motivations for doing so--we may be trying to attribute team under-performance to individuals, we may be hypothesizing who is likely to be transferred, etc.\n\nIt's not uncommon to ask \"How unlikely was their shooting performance this season?\" when looking at a player who has scored fewer goals than expected.[^1] For instance, if a striker only scores 8 goals on 12 [expected goals (xG)](https://theanalyst.com/na/2021/07/what-are-expected-goals-xg/), their \"underperformance\" of 4 goals is stark, especially if they had scored more goals than their xG in prior seasons.\n\n[^1]: I only consider non-penalty xG and goals for this post. The ability to score penalties at a high success rate is generally seen as a different skill set than the ability to score goals in open play.\n\nThe ratio of a player $p$'s goals $G_p$ to expected goals $xG_p$--the [\"performance\" ($PR_p$) ratio](/posts/xg-ratio-empirical-bayes/)--is a common, albeit [flawed](https://dtai.cs.kuleuven.be/sports/blog/biases-in-expected-goals-models-confound-finishing-ability), way of evaluating a player's shooting performance.[^2]\n\n[^2]: The raw difference between goals and xG is a reasonable measure of shooting performance, but it can \"hide\" shot volume. Is it fair to compare a player who takes 100 shots in a year and scores 12 goals on 10 xG with a player who takes 10 shots and scores 3 goals on 1 xG? The raw difference is +2 in both cases, indicating no difference in the shooting performance for the two players. However, their $PR_p$ would be 1.2 and 3 respectively, hinting at the former player's small sample size.\n\n$$\nPR_p = \\frac{G_p}{xG_p}\n$$\n\nAn $PR_p$ of 1 indicates that a player is scoring as many goals as expected; a ratio greater than 1 indicates overperformance; and a ratio less than 1 indicates underperformance. Our hypothetical player underperformed with $PR_p = \\frac{8}{12} = 0.67$.\n\nIn most cases, we have prior seasons of data to use when evaluating a player's $PR_p$ for a given season. For example, let's say our hypothetical player scored 14 goals on 10 xG ($PR_p = 1.4$) in the season prior, and 12 goals on 8 xG ($PR_p = 1.5$) before that. A $PR_p = 0.67$ after those seasons seems fairly unlikely, especially compared to an \"average\" player who has a $PR_p = 1$ every year.\n\nSo how do we put a number on the unlikeliness of the $PR_p = 0.67$ for our hypothetical player, accounting for their prior season-long performances?\n\n### Data\n\nI'll be using public data from [FBref](https://fbref.com/) for the 2018/19 - 2023/24 seasons of the [the Big Five European soccer leagues](https://fbref.com/en/comps/Big5/Big-5-European-Leagues-Stats), updated through May 7. Fake data is nice for examples, but ultimately we want to test our methods on real data. Our intuition about the results can be a useful caliber of the sensibility of our results.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Get shot data\"}\nraw_shots <- worldfootballR::load_fb_match_shooting(\n  country = COUNTRIES,\n  tier = TIERS,\n  gender = GENDERS,\n  season_end_year = SEASON_END_YEARS\n)\n#> → Data last updated 2024-05-07 17:52:59 UTC\n\nnp_shots <- raw_shots |> \n  ## Drop penalties\n  dplyr::filter(\n    !dplyr::coalesce((Distance == '13' & round(as.double(xG), 2) == 0.79), FALSE)\n  ) |> \n  dplyr::transmute(\n    season_end_year = Season_End_Year,\n    team = Squad,\n    player_id = Player_Href |> dirname() |> basename(),\n    player = Player,\n    match_date = lubridate::ymd(Date),\n    match_id = MatchURL |> dirname() |> basename(),\n    minute = Minute,\n    g = as.integer(Outcome == 'Goal'),\n    xg = as.double(xG)\n  ) |> \n  ## A handful of scored shots with empty xG\n  dplyr::filter(!is.na(xg)) |> \n  dplyr::arrange(season_end_year, player_id, match_date, minute)\n\n## Use the more commonly used name when a player ID is mapped to multiple names\n##   (This \"bug\" happens because worldfootballR doesn't go back and re-scrape data\n##   when fbref makes a name update.)\nplayer_name_mapping <- np_shots |> \n  dplyr::count(player_id, player) |> \n  dplyr::group_by(player_id) |> \n  dplyr::slice_max(n, n = 1, with_ties = FALSE) |> \n  dplyr::ungroup() |> \n  dplyr::distinct(player_id, player)\n\nplayer_season_np_shots <- np_shots |> \n  dplyr::summarize(\n    .by = c(player_id, season_end_year), \n    shots = dplyr::n(),\n    dplyr::across(c(g, xg), sum)\n  ) |> \n  dplyr::mutate(\n    pr = g / xg\n  ) |> \n  dplyr::left_join(\n    player_name_mapping,\n    by = dplyr::join_by(player_id)\n  ) |> \n  dplyr::relocate(player, .after = player_id) |> \n  dplyr::arrange(player_id, season_end_year)\nplayer_season_np_shots\n#> # A tibble: 15,327 × 7\n#>    player_id player          season_end_year shots     g    xg    pr\n#>    <chr>     <chr>                     <int> <int> <int> <dbl> <dbl>\n#>  1 0000acda  Marco Benassi              2018    70     5  4.01 1.25 \n#>  2 0000acda  Marco Benassi              2019    59     7  5.61 1.25 \n#>  3 0000acda  Marco Benassi              2020    20     1  1.01 0.990\n#>  4 0000acda  Marco Benassi              2022    10     0  0.99 0    \n#>  5 0000acda  Marco Benassi              2023    19     0  1.35 0    \n#>  6 000b3da6  Manuel Iturra              2018     2     0  0.41 0    \n#>  7 00242715  Moussa Niakhate            2018    16     0  1.43 0    \n#>  8 00242715  Moussa Niakhate            2019    10     1  1.5  0.667\n#>  9 00242715  Moussa Niakhate            2020    11     1  1.02 0.980\n#> 10 00242715  Moussa Niakhate            2021     9     2  1.56 1.28 \n#> # ℹ 15,307 more rows\n```\n:::\n\n\n\n\n\n\nFor illustrative purposes, we'll focus on one player in particular--[James Maddison](https://fbref.com/en/players/ee38d9c5/James-Maddison). Maddison has had a sub-par 2023/2024 season by his own standards, underperforming his xG for the first time since he started playing in the [Premier League](https://fbref.com/en/comps/9/Premier-League-Stats) in 2018/19.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Maddison's season-by-season data\"}\nplayer_season_np_shots |> dplyr::filter(player == 'James Maddison')\n#> # A tibble: 6 × 7\n#>   player_id player         season_end_year shots     g    xg    pr\n#>   <chr>     <chr>                    <int> <int> <int> <dbl> <dbl>\n#> 1 ee38d9c5  James Maddison            2019    81     6  5.85 1.03 \n#> 2 ee38d9c5  James Maddison            2020    74     6  5.36 1.12 \n#> 3 ee38d9c5  James Maddison            2021    75     8  3.86 2.07 \n#> 4 ee38d9c5  James Maddison            2022    72    12  7.56 1.59 \n#> 5 ee38d9c5  James Maddison            2023    83     9  7.12 1.26 \n#> 6 ee38d9c5  James Maddison            2024    55     4  5.02 0.797\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"More variables useful for the rest of the post\"}\nTARGET_SEASON_END_YEAR <- 2024\n\nplayer_np_shots <- player_season_np_shots |> \n  dplyr::mutate(\n    is_target = season_end_year == TARGET_SEASON_END_YEAR\n  ) |> \n  dplyr::summarize(\n    .by = c(is_target, player_id, player),\n    dplyr::across(\n      c(shots, g, xg),\n      \\(.x) sum(.x, na.rm = TRUE)\n    )\n  ) |> \n  dplyr::mutate(pr = g / xg) |> \n  dplyr::arrange(player, player_id, is_target)\n\nwide_player_np_shots <- player_np_shots |>\n  dplyr::transmute(\n    player_id, \n    player,\n    which = ifelse(is_target, 'target', 'prior'), \n    shots, g, xg, pr\n  ) |> \n  tidyr::pivot_wider(\n    names_from = which, \n    values_from = c(shots, g, xg, pr), \n    names_glue = '{which}_{.value}'\n  )\n\nall_players_to_evaluate <- wide_player_np_shots |> \n  tidyr::drop_na(prior_pr, target_pr) |> \n  dplyr::filter(\n    prior_shots >= 50,\n    target_shots >= 10,\n    prior_g > 0, \n    target_g > 0\n  )\n```\n:::\n\n\n## Methods and Analysis\n\nI'll present 3 approaches to contexutalizing the likelihood of a player underperforming relative to their prior $G / xG$ ratio, which I'll broadly call the \"performance ratio percentile\", $PRP_p$.\n\n1.  Weighted **percentile ranking**: Identify where a player's performance relative to their own past ranks among the whole spectrum of relative player performances.\n2.  **Resampling** from prior shot history: Quantify the likelihood of the observed outcome for a given player by resampling shots from their past.\n3.  Evaluating a player-specific **cumulative distribution function (CDF)**: Fit a distribution to represent a player's past set of season-long outcomes, then identify where the target season's outcome lies on that distribution.\n\nI'll discuss some of the strengths and weaknesses of each approach as we go along, then summarize the findings in the end.\n\nNote that I use \"prior\", or $\\text{target}'$, to refer to an aggregate of pre-2023/24 statistics, and \"target\" to refer to 2023/24. Here's what the distribution of $PR_{p,\\text{target}'}$ and $PR_{p,\\text{target}}$ looks like. The latter's distribution has a bit more noise--note the lump of players with ratios greater than 2--due to smaller sample sizes.\n\n![](raw_pr.png)\n\n### Approach 1: Weighted Percentile Ranking\n\nThe first approach I'll present is a handcrafted \"ranking\" method.\n\n1.  Calculate the proportional difference between the pre-target and target season performance ratios for all players $P$.\n\n$$\n\\delta PR_p = \\frac{PR_{p,\\text{target}} - PR_{p,\\text{target}'}}{PR_{p,\\text{target}'}}\n$$\n\n2.  Weight $\\delta PR^w_p$ by the player's $xG_p$ accumulated in prior seasons.[^3]\n\n[^3]: The weighting emphasizes scenarios where a veteran player, typically overperforming or at worst neutral, suddenly underperforms, as opposed to a second-year player experiencing similar downturns.\n\n$$\n\\delta PR^w_p = \\delta PR_p * xG_p\n$$\n\n3.  Calculate the the performance percentile $PRP_p$ as a percentile rank of ascending $\\delta PR^w_p$, i.e. more negative $\\delta PR^w_p$ values correspond to a lower $PRP_p$ percentile.[^4]\n\n[^4]: Percentiles greater than 50% generally correspond with players who have overperformed, so really the bottom 50% are the players we're looking at when we're considering underperformance.\n\nThis seems really straightforward, right? Indeed, with the data prepped in the correct manner, it is straightforward to calculate.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Approach 1 implementation\"}\n## `prp` for \"performance ratio percentile\"\nall_prp_approach1 <- all_players_to_evaluate |> \n  dplyr::transmute(\n    player,\n    prior_pr,\n    target_pr,\n    prior_xg,\n    weighted_delta_o = prior_shots * (target_pr - prior_pr) / prior_pr,\n    prp = dplyr::percent_rank(weighted_delta_o)\n  ) |> \n  dplyr::arrange(prp)\n\nmaddison_prp_approach1 <- all_prp_approach1 |> \n  dplyr::filter(player == 'James Maddison')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Approach 1 output for Maddison\"}\nmaddison_prp_approach1 |> dplyr::select(player, prior_pr, target_pr, prp)\n#> # A tibble: 1 × 4\n#>   player         prior_pr target_pr    prp\n#>   <chr>             <dbl>     <dbl>  <dbl>\n#> 1 James Maddison     1.38     0.797 0.0233\n```\n:::\n\n\nThis approach finds Maddison's 2023/24 $PR_p$ of 0.797 to be about a 2nd percentile outcome. Among the 602 players evaluated, Maddison's 2023/24 $PR_p$ ranks as the 15th lowest.\n\nFor context, here's a look at the top 10 most unlikely outcomes for the 2023/24 season.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Approach 1 output, top 10 underperforming players\"}\nall_prp_approach1 |> head(10) |> dplyr::select(player, prior_pr, target_pr, prp)\n#> # A tibble: 10 × 4\n#>    player              prior_pr target_pr     prp\n#>    <chr>                  <dbl>     <dbl>   <dbl>\n#>  1 Ciro Immobile          1.23      0.503 0      \n#>  2 Giovanni Simeone       1.03      0.306 0.00166\n#>  3 Nabil Fekir            1.14      0.490 0.00333\n#>  4 Wahbi Khazri           1.11      0.322 0.00499\n#>  5 Kevin Volland          1.18      0.388 0.00666\n#>  6 Adrien Thomasson       1.18      0.282 0.00832\n#>  7 Timo Werner            0.951     0.543 0.00998\n#>  8 Gaëtan Laborde         1.02      0.546 0.0116 \n#>  9 Fabián Ruiz Peña       1.67      0.510 0.0133 \n#> 10 Benjamin Bourigeaud    1.12      0.503 0.0150\n```\n:::\n\n\n[Ciro Immobile](https://fbref.com/en/players/4431aed2/Ciro-Immobile) tops the list, with several other notable attacking players who had less than stellar seasons.\n\n#### Discussion\n\nOverall, I'd say that this methodology seems to generate fairly reasonable results, but certainly has its flaws.\n\n-   **Subjectivity in Weighting**: The choice to weight the difference in performance ratios by pre-2023/24 xG is inherently subjective. While it's important to have some form of weighting--so as to avoid disproportionately emphasizing players with a shorter history of past shots or who shoot relatively few shots in the target season--alternative weighting strategies could lead to significantly different rankings.\n-   **Sensitivity to Player Pool**: The percentile ranking of a player's $PR_{p,\\text{target}}$ unlikeliness is highly sensitive to the comparison group. For instance, comparing forwards to defenders could skew results due to generally higher variability in defenders' goal-to-expected goals ratios. Moreover, if we for some reason chose to evaluate a set of players from lower tier leagues who generally scores less goals than their expected goals, even players who can simply maintain a $PR_p = 1$ might appear more favorably than they would when compared to Big Five league players. This potential for selection bias underlines the importance of carefully choosing the comparison set of players.\n\n### Approach 2: Resampling from Prior Shot History\n\nThere's only so much you can do with player-season-level data; shot-level data can help us more robustly understand and quantify the uncertainty of shooting outcomes.\n\nHere's a \"resampling\" approach to quantify the performance ratio percentile $PRP_p$ of a player in the target season:\n\n1.  Sample $N_{p,\\text{target}}$ shots from a player's past shots $S_{p,\\text{target}'}$. Repeat this for $R$ resamples.[^5]\n\n2.  Count the number of resamples $r$ in which the outperformance ratio $\\hat{PR}_{p,\\text{target}'}$ of the sampled shots is less than or equal to the observed $PR_{p,\\text{target}}$ in the target season for the player. The proportion $PRP_p = \\frac{r}{R}$ represents the unlikeness of a given player's observed $PR_{p,\\text{target}}$ (or worse) in the target season.\n\n[^5]: $N_p$ should be set equal to the number of shots a player has taken in the target season. $R$ should be set to some fairly large number, so as to achieve stability in the results.\n\nHere's how that looks in code.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Approach 2 implementation\"}\nR <- 1000\nresample_player_shots <- function(\n    shots, \n    n_shots_to_sample, \n    n_sims = R,\n    replace = TRUE,\n    seed = 42\n) {\n  \n  withr::local_seed(seed)\n  purrr::map_dfr(\n    1:n_sims,\n    \\(.sim) {\n      sampled_shots <- shots |> \n        slice_sample(n = n_shots_to_sample, replace = replace)\n      \n      list(\n        sim = .sim,\n        xg = sum(sampled_shots$xg),\n        g = sum(sampled_shots$g),\n        pr = sum(sampled_shots$g) / sum(sampled_shots$xg)\n      )\n    }\n  )\n}\n\nresample_one_player_pr <- function(shots, target_season_end_year) {\n  target_shots <- shots |>\n    dplyr::filter(season_end_year == target_season_end_year)\n  \n  prior_shots <- shots |>\n    dplyr::filter(season_end_year < target_season_end_year)\n  \n  prior_shots |> \n    resample_player_shots(\n      n_shots_to_sample = nrow(target_shots)\n    )\n}\n\nresample_player_pr <- function(shots, players, target_season_end_year = TARGET_SEASON_END_YEAR) {\n  purrr::map_dfr(\n    players,\n    \\(.player) {\n      shots |> \n        dplyr::filter(player == .player) |> \n        resample_one_player_pr(\n          target_season_end_year = target_season_end_year\n        ) |> \n        dplyr::mutate(\n          player = .player\n        )\n    }\n  )\n}\n\nmaddison_resampled_pr <- np_shots |> \n  resample_player_pr(\n    players = 'James Maddison'\n  ) |> \n  dplyr::inner_join(\n    wide_player_np_shots |> \n      dplyr::select(\n        player,\n        prior_pr,\n        target_pr\n      ),\n    by = dplyr::join_by(player)\n  ) |> \n  dplyr::arrange(player)\n\nmaddison_prp_approach2 <- maddison_resampled_pr |>\n  dplyr::summarize(\n    .by = c(player, prior_pr, target_pr),\n    prp = sum(pr <= target_pr) / n()\n  ) |> \n  dplyr::arrange(player)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Approach 2 output for Maddison\"}\nmaddison_prp_approach2 |> dplyr::select(player, prior_pr, target_pr, prp)\n```\n:::\n\n\nThe plot below should provide a bit of visual intuition as to what's going on.\n\n![](maddison_prp_approach2.png)\n\nThese results imply that Maddison's 2023/24 $G / xG$ ratio of 0.797 (or worse) occurs in 10.9% of simulations, i.e. an 11th percentile outcome. That's a bit higher than what the first approach showed.\n\nHow can we feel confident about this approach? Well, in the first approach, we sort of implicitly assumed that underperformance should be uniform across all players, hence the percentile ranking. We should see if the same bears out with this second approach.\n\nThe plot below shows a histogram of the performance ratio percentile across all players, where each player's estimated unlikelihood is grouped into a decile.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Approach 2 implementation for all players\"}\nall_resampled_pr <- np_shots |> \n  resample_player_pr(\n    players = all_players_to_evaluate$player\n  ) |> \n  dplyr::inner_join(\n    wide_player_np_shots |> \n      ## to make sure we just one Rodri, Danilo, and Nicolás González \n      dplyr::filter(player_id %in% all_players_to_evaluate$player_id) |> \n      dplyr::select(\n        player,\n        prior_pr,\n        target_pr,\n        prior_shots,\n        target_shots\n      ),\n    by = dplyr::join_by(player)\n  ) |> \n  dplyr::arrange(player, player)\n\nall_prp_approach2 <- all_resampled_pr |>\n  dplyr::summarize(\n    .by = c(player, prior_pr, target_pr, prior_shots, target_shots),\n    prp = sum(pr <= target_pr) / dplyr::n()\n  ) |> \n  dplyr::arrange(prp)\n```\n:::\n\n\n\n\n\n\n![](all_prp_approach2.png)\n\nIndeed, the histogram shows a fairly uniform distribution, with a bit of irregularity at the very edges.\n\nLooking at who is in the lower end of the leftmost decile, we see some of the same names--Immobile and [Savanier](https://fbref.com/en/players/6bde367b/Teji-Savanier)--among the ten underperformers. (Withholding judgment on the superiority of any methodology, we can find some solace in seeing some of the same names among the most unlikely underperformers here as we did with approach 1.)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Approach 2 output, top 10 underperforming players\"}\nall_prp_approach2 |> head(10) |> dplyr::select(player, prior_pr, target_pr, prp)\n#> # A tibble: 10 × 4\n#>    player                    prior_pr target_pr   prp\n#>    <chr>                        <dbl>     <dbl> <dbl>\n#>  1 Pierre-Emerick Aubameyang     1.07     0.636 0.009\n#>  2 Alex Baena                    1.54     0.326 0.01 \n#>  3 Amine Harit                   1.27     0.262 0.01 \n#>  4 Erling Haaland                1.26     0.897 0.013\n#>  5 Kevin Volland                 1.18     0.388 0.015\n#>  6 Antonio Sanabria              1.05     0.380 0.018\n#>  7 Kevin Behrens                 1.39     0.673 0.019\n#>  8 Elye Wahi                     1.38     0.770 0.021\n#>  9 Ansu Fati                     1.31     0.430 0.024\n#> 10 M'Bala Nzola                  1.10     0.274 0.025\n```\n:::\n\n\nOne familiar face in the printout above is [Manchester City's striker Erling Haaland](https://fbref.com/en/players/1f44ac21/Erling-Haaland), whose underperformance this season has been called among [fans and the media](https://theathletic.com/5430355/2024/04/20/erling-haaland-manchester-city-human/). His sub-par performance this year ranked as a 9th percentile outcome by approach 1, which is very low, but not quite as low as what this approach finds (1st percentile).\n\n#### Discussion\n\n-   **Assumption of Shot Profile Consistency**: We assume that a player's past shot behavior accurately predicts their future performance. This generally holds unless a player changes their role or team, or is recovering from an injury. But there are other exceptions as well. For example, Haaland has taken a lot more headed shots this season, despite playing effectively the same role on mostly the same team from last season The change in Haaland's shot profile this year conflicts with the assumption of a consistent shot profile, perhaps explaining why this resampling approach finds Haaland's shooting performance to be more unlikely the percentile ranking approach.\n-   **Non-Parametric Nature**: This method does not assume any specific distribution for a player’s performance ratios; instead, it relies on the stability of a player's performance over time. The resampling process itself shapes the outcome distribution, which can vary significantly between players with different shooting behaviors, such as a forward versus a defender.\n-   **Computational Demands**: The resampling approach requires relatively more computational resources than the prior approach, especially without parallel processing. Even a relatively small number of resamples, such as $R=1000$, can take a few second per player to compute.\n\n### Approach 3: Evaluating a Player-Specific Cumulative Distribution Function (CDF)\n\nIf we assume that the set of goals-to-xG ratios come from a [Gamma data-generating process](https://en.wikipedia.org/wiki/Gamma_process), then we can leverage the properties of a player-level [Gamma distribution](https://en.wikipedia.org/wiki/Gamma_distribution) to assess the unlikelihood of a players $PR_p$ ratio.\n\nTo calculate the underperforming unlikeliness $PRP_p$:\n\n1.  Estimate a Gamma distribution $\\Gamma_{p,\\text{target}'}$ to model a player's true outperformance ratio $O_{p}$ across all prior shots, excluding those in the target season--$\\hat{PR}_{p,\\text{target}'}$.\n\n2.  Calculate the probability that $\\hat{PR}_{p,\\text{target}'}$ is less than or equal to the player's observed $PR_{p,\\text{target}}$ in the target season using the Gamma distribution's [cumulative distribution function (CDF)](https://en.wikipedia.org/wiki/Cumulative_distribution_function).\n\nWhile that may sound daunting, I promise that it's not.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Approach 3 implementation\"}\nN_SIMS <- 10000\n\nSHOT_TO_SHAPE_MAPPING <- list(\n  'from' = c(50, 750),\n  'to' = c(1, 25)\n)\n## Fix the gamma distribution's \"median\" to be shaped around the player's past\n##   historical G/xG ratio (with minimum shape value of 1, so as to prevent a \n##   monotonically decreasing distribution function).\n## Fit larger shape and rate parameters when the player has a lot of prior shots, \n##   so as to create a tighter Gamma distibution.\nestimate_one_gamma_distributed_pr  <- function(\n    shots,\n    target_season_end_year\n) {\n  player_np_shots <- shots |> \n    dplyr::mutate(is_target = season_end_year == target_season_end_year)\n  \n  prior_player_np_shots <- player_np_shots |> \n    dplyr::filter(!is_target)\n  \n  target_player_np_shots <- player_np_shots |> \n    dplyr::filter(is_target)\n  \n\n  agg_player_np_shots <- player_np_shots |>\n    dplyr::summarize(\n      .by = c(is_target),\n      shots = dplyr::n(),\n      dplyr::across(c(g, xg), \\(.x) sum(.x))\n    ) |> \n    dplyr::mutate(pr = g / xg)\n  \n  agg_prior_player_np_shots <- agg_player_np_shots |> \n    dplyr::filter(!is_target)\n  \n  agg_target_player_np_shots <- agg_player_np_shots |> \n    dplyr::filter(is_target)\n\n  shape <- dplyr::case_when(\n    agg_prior_player_np_shots$shots < SHOT_TO_SHAPE_MAPPING$from[1] ~ SHOT_TO_SHAPE_MAPPING$to[2],\n    agg_prior_player_np_shots$shots > SHOT_TO_SHAPE_MAPPING$from[2] ~ SHOT_TO_SHAPE_MAPPING$to[2],\n    TRUE ~ scales::rescale(\n      agg_prior_player_np_shots$shots, \n      from = SHOT_TO_SHAPE_MAPPING$from, \n      to = SHOT_TO_SHAPE_MAPPING$to\n    )\n  )\n  list(\n    'shape' = shape,\n    'rate' = shape / agg_prior_player_np_shots$pr\n  )\n}\n\nestimate_gamma_distributed_pr <- function(\n    shots,\n    players,\n    target_season_end_year\n) {\n  \n  purrr::map_dfr(\n    players,\n    \\(.player) {\n      params <- shots |> \n        dplyr::filter(player == .player) |> \n        estimate_one_gamma_distributed_pr(\n          target_season_end_year = target_season_end_year\n        )\n      \n      list(\n        'player' = .player,\n        'params' = list(params)\n      )\n    }\n  )\n}\n\nmaddison_gamma_pr <- np_shots |> \n  estimate_gamma_distributed_pr(\n    players = 'James Maddison',\n    target_season_end_year = TARGET_SEASON_END_YEAR\n  ) |> \n  dplyr::inner_join(\n    wide_player_np_shots |> \n      dplyr::select(\n        player,\n        prior_pr,\n        target_pr\n      ),\n    by = dplyr::join_by(player)\n  ) |> \n  dplyr::arrange(player)\n\nmaddison_prp_approach3 <- maddison_gamma_pr |> \n  dplyr::mutate(\n    prp = purrr::map2_dbl(\n      target_pr,\n      params,\n      \\(.target_pr, .params) {\n        pgamma(\n          .target_pr, \n          shape = .params$shape, \n          rate = .params$rate,\n          lower.tail = TRUE\n        )\n      }\n    )\n  ) |> \n  tidyr::unnest_wider(params)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Approach 3 output for Maddison\"}\nmaddison_prp_approach3 |> dplyr::select(player, prior_pr, target_pr, prp)\n#> # A tibble: 1 × 4\n#>   player         prior_pr target_pr    prp\n#>   <chr>             <dbl>     <dbl>  <dbl>\n#> 1 James Maddison     1.38     0.797 0.0469\n```\n:::\n\n\nWe see that Maddison's 2023/24 $PR_{p,\\text{target}}$ ratio of 0.797 (or worse) is about a 5th percentile outcome given his prior shot history.\n\nTo gain some intuition around this approach, we can plot out the Gamma distributed estimate of Maddison's $PR_p$. The result is a histogram that looks not all that dissimilar to the one from before with resampled shots, just much smoother (since this is a \"parametric\" approach).\n\n![](maddison_prp_approach3.png)\n\nAs with approach 2, we should check to see what the distribution of underperforming unlikeliness looks like--we should expect to see a somewhat uniform distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Approach 3 for all players\"}\nall_gamma_pr <- np_shots |> \n  estimate_gamma_distributed_pr(\n    players = all_players_to_evaluate$player,\n    target_season_end_year = TARGET_SEASON_END_YEAR\n  ) |> \n  dplyr::inner_join(\n    wide_player_np_shots |> \n      dplyr::filter(\n        player_id %in% all_players_to_evaluate$player_id\n      ) |> \n      dplyr::select(\n        player,\n        prior_pr,\n        target_pr\n      ),\n    by = dplyr::join_by(player)\n  ) |> \n  dplyr::arrange(player)\n\nall_prp_approach3 <- all_gamma_pr |> \n  dplyr::mutate(\n    prp = purrr::map2_dbl(\n      target_pr,\n      params,\n      \\(.target_pr, .params) {\n        pgamma(\n          .target_pr, \n          shape = .params$shape, \n          rate = .params$rate,\n          lower.tail = TRUE\n        )\n      }\n    )\n  ) |> \n  tidyr::unnest_wider(params) |> \n  dplyr::arrange(prp)\n```\n:::\n\n\n![](all_prp_approach3.png)\n\nThis histogram has a bit more distortion than our resampling approach, so perhaps it's a little less calibrated.\n\nLooking at the top 10 strongest underperformers, 2 of the names here--[Volland](https://fbref.com/en/players/64f69877/Kevin-Volland) [Sanabria](https://fbref.com/en/players/0a447501/Antonio-Sanabria)--are shared with approach 2's top 10, and 7 are shared with approach 1's top 10.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Approach 3 output, top 10 underperforming players\"}\nall_prp_approach3 |> head(10) |> dplyr::select(player, prior_pr, target_pr, prp)\n#> # A tibble: 10 × 4\n#>    player           prior_pr target_pr      prp\n#>    <chr>               <dbl>     <dbl>    <dbl>\n#>  1 Ciro Immobile        1.23     0.503 0.000238\n#>  2 Giovanni Simeone     1.03     0.306 0.000248\n#>  3 Adrien Thomasson     1.18     0.282 0.000346\n#>  4 Wahbi Khazri         1.11     0.322 0.000604\n#>  5 Kevin Volland        1.18     0.388 0.00132 \n#>  6 Nabil Fekir          1.14     0.490 0.00256 \n#>  7 Fabián Ruiz Peña     1.67     0.510 0.00271 \n#>  8 Antonio Sanabria     1.05     0.380 0.00796 \n#>  9 Téji Savanier        1.42     0.548 0.0103  \n#> 10 Jordan Veretout      1.16     0.360 0.0105\n```\n:::\n\n\nWe can visually check the consistency of the results from this method with the prior two with scatter plots of the estimated performance ratio percentile from each.\n\n![](all_prp.png)\n\nIf two of the approaches were perfectly in agreement, then each point, representing one of the 602 evaluated players, would fall along the 45-degree slope 1 line.\n\nWith that in mind, we can see that approach 3 is more **precise** agrees with approach 1, although approach 3 tends to assign slightly higher percentiles to players on the whole. The results from approaches 2 and 3 also have a fair degree of agreement, and the results are more uniformly calibrated.\n\n#### Discussion\n\n-   **Parametric Nature**: The reliance on a Gamma distribution for modeling a player’s performance is both a strength and a limitation. The Gamma distribution is apt for positive, skewed continuous variables, making it suitable for modeling goals-to-xG ratios. However, the dependency on a single distribution type may restrict the scope of analysis.\n-   **Sensitivity to Distribution Parameters**: The outcomes of this methodology are highly sensitive to the parameters defining each player's Gamma distribution. Small adjustments in shape or rate parameters can significantly alter the distribution, causing substantial shifts in the percentile outcomes of player performances. This sensitivity underscores the need for careful parameter selection and calibration.\n-   **Flexibility of the Model**: Despite its sensitivity, the Gamma distribution offers considerable flexibility. It allows for fine-tuning of the model to better fit the data, which can be advantageous for capturing the nuances of different players’ shot profiles.\n\n# Conclusion\n\nHere's a summary of the biggest pros and cons of each approach, along with the result for Maddison.\n\n| Approach | Description                            | Biggest Pro     | Biggest Con                                    | Maddison 2023/24 Underperformance Unlikeliness |\n|----------|----------------------------------------|-----------------|------------------------------------------------|------------------------------------------------|\n| 1        | Percentile Ranking                     | customizable    | sensitive to the choice of players to evaluate | 2nd percentile                                 |\n| 2        | Resampling                             | non-parametric  | limited by player's shot history               | 11th percentile                                |\n| 3        | Cumulative Distribution Function (CDF) | flexibility[^6] | sensitive to choice of distribution parameters | 5th percentile                                 |\n\n[^6]: Well, it's \"flexible\" to the extent that a statistical distribution can be flexible.\n\nI personally prefer either the second or third approach. In practice, perhaps the best thing to do is take an ensemble average of each approach, as they each have their pros and cons.\n\n## Potential Future Research\n\n1.  **Can these approaches be applied to teams or managers to understand the unlikeliness of their season-long outcomes?**\n\nI think the answer is \"yes\", for the resampling approach. The non-parametric nature of resampling makes it easy to translate to other \"levels of aggregation\", i.e. a set of players under a manager or playing as a team.\n\n2.  **Can we accurately attribute a percentage of underperformance to skill and luck?**\n\nEh, I don't know about \"accurately\", especially at the player-level.The [R-squared](https://en.wikipedia.org/wiki/Coefficient_of_determination) of [year-over-year player-level G / xG ratios is nearly zero](https://www.americansocceranalysis.com/home/2023/8/28/the-replication-project-measuring-shooting-overperformance). If we equate \"skill\" to \"percent of variance explained in year-over-year correlations of a measure (i.e. G / xG)\", then I suppose the answer is that basically 0% of seasonal over- or under-performance is due to innate factors; rather, we'd attribute all variation to \"luck\" (assuming that their \"skill\" and \"luck\" are the only factors that can explain residuals). That's not all that compelling, although it may be the reality.\n\n[My prior work on \"meta-metrics\" for soccer](/posts/soccer-meta-analytics/) perhaps has a more compelling answer. The \"stability\" measure defined in that post for $G / xG$ comes out to about 70% (out of 100%).\n\n# Appendix\n\n### Approach 0: $t$-test\n\nIf you have some background in statistics, applying a [$t$-test](https://en.wikipedia.org/wiki/Student%27s_t-test) (using shot-weighted averages and standard deviations) may be an approach that comes to mind.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Approach 0\"}\nprp_approach0 <- player_season_np_shots |> \n  dplyr::semi_join(\n    all_players_to_evaluate |> dplyr::select(player_id),\n    by = dplyr::join_by(player_id)\n  ) |> \n  dplyr::filter(season_end_year < TARGET_SEASON_END_YEAR) |> \n  dplyr::summarise(\n    .by = c(player),\n    mean = weighted.mean(pr, w = shots),\n    ## could also use a function like Hmisc::wtd.var for weighted variance\n    sd = sqrt(sum(shots * (pr - weighted.mean(pr, w = shots))^2) / sum(shots))\n  ) |> \n  dplyr::inner_join(\n    wide_player_np_shots |> \n      dplyr::select(player, prior_pr, target_pr),\n    by = dplyr::join_by(player)\n  ) |> \n  dplyr::mutate(\n    z_score = (target_pr - mean) / sd,\n    ## multiply by 2 for a two-sided t-test\n    prp = pnorm(-abs(z_score))\n  ) |> \n  dplyr::select(-c(mean, sd)) |> \n  dplyr::arrange(player)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"Approach 0 output\"}\nprp_approach0 |> \n  dplyr::filter(player == 'James Maddison') |> \n  dplyr::select(player, prior_pr, target_pr, prp)\n#> # A tibble: 1 × 4\n#>   player         prior_pr target_pr    prp\n#>   <chr>             <dbl>     <dbl>  <dbl>\n#> 1 James Maddison     1.38     0.797 0.0543\n```\n:::\n\n\nIn reality, this isn't giving us a percentage of unlikelihood of the outcome. Rather, the p-value measures the probability of underformance as extreme as the underperformance observed in 2023/24 if the null hypothesis is true. The null hypothesis in this case would be that there is no significant difference between the player's actual $PR_p$ in the 2023/24 season and the distribution of performance ratios observed in previous seasons.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}