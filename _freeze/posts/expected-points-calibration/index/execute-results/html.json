{
  "hash": "60971bb409f9c4d86b624b6b5a7334ea",
  "result": {
    "markdown": "---\ntitle: Calibrating Implied Match Probabilities in Soccer \ndescription: Using calibration to improve the match outcome probabilities implied by expected points\ndate: 2023-09-10\ndraft: true\ncategories:\n  - r\n  - soccer\nimage: foo.png\nexecute: \n  code-fold: false\n  eval: false\n  include: true\n  echo: true\n---\n\n\n## Introduction\n\nThis blog post demonstrates how to adjust [expected goals (xG)](https://theanalyst.com/na/2021/07/what-are-expected-goals-xg/) to [more accurately predict](https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html) [match points](https://en.wikipedia.org/wiki/Three_points_for_a_win) for soccer (football) teams. By applying a technique called [calibration](https://en.wikipedia.org/wiki/Calibration_(statistics))[^1], we can better align [**expected points (xPts)**](https://www.bettingodds.com/news/what-are-expected-points-xp-football-betting) with teams' actual performance.\n\n[^1]: or [\"remediation\"](https://www.tidymodels.org/learn/models/calibration/#remediation)\n\nIf you don't care at all about what \"expected points\" are or simply just want to see how to do such a model calibration with R and [the `{probably}` package](https://probably.tidymodels.org/), feel free to skip past the \"Introduction\" section.\n\n### Expected Points\n\nIn [a prior post](/posts/opta-xg-model-calibration/), I showed how to calculate **expected points (xPts)** from expected goals (xG) for the beautiful game of soccer (football).\n\n::: {.callout-note collapse=\"true\"}\n## xG and xPts Definitions\n\n-   **xG** is the predicted probability that a shot will be a goal, based on contextual features like the distance of the shot from the goal.\n-   **xPts** is a number between 0 and 3 assigned to each team in a match estimated deterministically from the xG of each shot in the match. Teams that accumulate more xG than their opponents in the match are more likely to have xPts closer to 3.\n:::\n\nOne thing that is not traditionally accounted for with xG and, consequently, xPts, is [**game state**](https://theathletic.com/2730755/2021/07/28/the-athletics-football-analytics-glossary-explaining-xg-ppda-field-tilt-and-how-to-use-them/), i.e. whether a team is in losing, drawing, or winning when some event (e.g. a shot) occurs. To account for this, we need to make xG \"aware\" of the game state.\n\nWe could add an input feature to the xG model. However:\n\n1.  I'm not the creator of the xG model that I'll be using, so I can't actually do that.\n2.  Further, and more importantly, I don't think this is a good idea, based on **conceptual integrity**.\n\nOn the latter point--traditional xG models focus on more directly attributable factors such as player positioning and the intrinsic attributes of the shot itself; they remain agnostic to elements like player identity and weather conditions. Sure, we could improve an xG model by having a dummy variable for whether the shot taker is Lionel Messi, but doing so would be shifting away from the intention of a typical xG model.[^2]\n\n[^2]: This isn't to discredit [research](https://statsbomb.com/wp-content/uploads/2022/09/Tahmeed-Tureen-and-Sigrid-Olthof-%E2%80%93-Estimated-Player-Impact-EPI-Quantifying-The-Effects-Of-Individual-Players-On-Football-Actions-Using-Hierarchical-Statistical-Models.pdf) conducted where player effects are modeled as part of xG---I actually really like doing that kind of thing when trying to tease out estimates of player skill. However, for the sole purpose of quantifying the innate quality of a shot, adding inputs that aren't directly related to the attributes of a shot, such as game state, feel unjustified, even if they would improve model performance.\n\nWith that being said, when we're applying xG for a separate task, such as for calculating xPts, accounting for game state feels valid. We can do so with a second model that \"calibrates\" the output of the original model. In this context, we'd aim to align the xG model's output with the actual goal conversion rate, taking into account the game state.[^3]\n\n[^3]: You could also calibrate the output of a model to achieve marginal gains when there are no external factors you want to account for.\n\nSo let's dive in.\n\n## Analysis\n\n### Data\n\nWe'll be using data from [FBref](https://fbref.com/), which gets its xG from [Opta](https://www.statsperform.com/opta/). We'll limit the scope to the 2017/18 through 2022/23 seasons for the English Premier League. This post isn't about data collection, so I'll skip those details.\n\nHere's a glance at the data frame I'm working with. Note that there is one row per shot.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(dplyr)\nshots |> \n  dplyr::select(\n    shot_id,\n    team,\n    player,\n    is_goal,\n    pre_shot_game_state,\n    .pred_yes, ## xg\n    .pred_no   ## 1 - xg\n  )\n\n#> # A tibble: 56,872 × 7\n#>    shot_id     team     player is_goal pre_shot_game_state .pred_yes .pred_no\n#>    <chr>       <chr>    <chr>  <fct>   <fct>                   <dbl>    <dbl>\n#>  1 0014076a-01 Arsenal  Henri… no      neutral                  0.03     0.97\n#>  2 0014076a-02 Arsenal  Henri… no      neutral                  0.06     0.94\n#>  3 0014076a-03 West Ha… Marko… no      neutral                  0.08     0.92\n#>  4 0014076a-04 West Ha… Marko… no      neutral                  0.03     0.97\n#>  5 0014076a-05 West Ha… Marko… yes     neutral                  0.05     0.95\n#>  6 0014076a-06 Arsenal  Aaron… no      leading                  0.11     0.89\n#>  7 0014076a-07 Arsenal  Nacho… yes     trailing                 0.6      0.4 \n#>  8 0014076a-08 West Ha… Micha… no      neutral                  0.07     0.93\n#>  9 0014076a-09 West Ha… Felip… no      neutral                  0.07     0.93\n#> 10 0014076a-10 Arsenal  Shkod… no      neutral                  0.02     0.98\n#> # ℹ 56,862 more rows\n```\n:::\n\n\n::: {.callout-note collapse=\"false\"}\n## `shots` Data Dictionary\n\nWhile several of these columns should be self-explanatory, e.g. `team` and `player`, some could use an explanation:\n\n-   `.pred_yes`: xG[^4]\n-   `.pred_no`: 1 minus xG\n-   `pre_shot_game_state`: whether the team of the player taking the shot was winning (`\"leading\"`), drawing (`\"neutral\"`), or losing (`\"trailing\"`) the match before the shot was taken[^5]\n:::\n\n[^4]: I've found that `{probably}` needs a column for both the probability of \"success\" and \"failure\", hence the seeming redundancy between `.pred_yes` and `.pred_no`. More broadly, these column names should correspond with `{.pred}_{level1}` and `.pred_{level2}` for binary classification, where the target variable has factor levels `{level1}` and `{level2}`. (`{tidymodels}` expects the target variable to be a factor.)\n\n[^5]: I intentionally emphasize that the game state feature is with respect to the score prior to the outcome of the shot. It would be easy to calculate game state based on the score after the outcome of a shot, but that would be [\"leaking\"](https://www.kaggle.com/code/alexisbcook/data-leakage) information that could artificially enhance the model calibration.\n\nLet's start by taking a look at the calibration of the Opta xG model, splitting by game state. (Note that this uses `probably::cal_plot_breaks()`.)\n\n\n\n\n\n![](no_pre_shot_game_state_xg_calibration.png)\n\n### Calibration Modeling\n\nNow we **train** a model for calibration, grouping based on game state. (Well, really there are three models, one for each level of `pre_shot_game_state`.) I've opted for [Beta calibration](https://probably.tidymodels.org/reference/cal_estimate_beta.html) over alternatives like [logistic calibration](https://probably.tidymodels.org/reference/cal_estimate_logistic.html). Beta calibration [tends to provide superior probability estimates](https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-11/issue-2/Beyond-sigmoids--How-to-obtain-well-calibrated-probabilities-from/10.1214/17-EJS1338SI.full), especially with skewed data like xG, where most values tend towards 0.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(probably)\n\nbeta_cal_model <- probably::cal_estimate_beta(\n  shots,\n  truth = is_goal,\n  estimate = dplyr::starts_with('.pred'),\n  .by = pre_shot_game_state\n)\nbeta_cal_model\n#> ── Probability Calibration \n#> Method: Beta calibration\n#> Type: Binary\n#> Source class: Data Frame\n#> Data points: 56,872, split in 3 groups\n#> Truth variable: `is_goal`\n#> Estimate variables:\n#> `.pred_no` ==> no\n#> `.pred_yes` ==> yes\n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## How `{probably}` Implements Beta Calibration\n\nAt time of writing, this is implemented like so \"under the hood\".\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(purrr)\nlibrary(betacal)\nlibrary(rlang) ## for .env and .data\n\npurrr::map(\n  unique(shots$pre_shot_game_state),\n  function(pre_shot_game_state) {\n    filt_shots <- dplyr::filter(\n      shots,\n      .data$pre_shot_game_state == .env$pre_shot_game_state\n    )\n    betacal::beta_calibration(\n      p = filt_shots$.pred_no,\n      y = filt_shots$is_goal == 'no',\n      parameters = 'abm'\n    )\n  }\n)\n```\n:::\n\n\nAs we can see, there's just one dependent variable! After all, calibration is pretty straightforward--we leverage the original model output and the known target label to improve the model output.\n:::\n\n\n\n\n\n::: {.callout-note collapse=\"true\"}\n## Calibration Without a Grouping Variable\n\nTaking one step back, I should note that we could achieve better model performance compared to raw xG ***without*** accounting for a \"grouping\" variable, e.g. game state. Indeed, this is what is typically meant with calibration. By definition, calibration is\n\n$$\n\\hat{p} = \\Pr(Y|\\hat{p})\n$$ {#eq-calibration}\n\nwhere $Y$ is the target variable of interest, and $\\hat{p}$ is the predicted probability of our classification model. (Note no exogenous variables.) Implementation-wise, we'd just take out the `.by` variable to our call to `probably::cal_estimate_beta()`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nprobably::cal_estimate_beta(\n  shots,\n  truth = is_goal,\n  estimate = dplyr::starts_with('.pred')\n)\n```\n:::\n\n:::\n\nWith the fitted calibration models, let's **apply** the Beta calibration procedure to our shots data set.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nbeta_cal_shots <- probably::cal_apply(\n  shots,\n  beta_cal_model\n)\n```\n:::\n\n\nBelow is a plot that shows how the Beta calibration has adjusted the raw **\"uncalibrated\"** xG values.\n\n\n\n\n\n![](uncalibrated_vs_calibrated_xg.png)\n\nPutting the **calibrated** xG along side the original xG in the calibration plot that we made earlier, we can see a slight visual improvement.\n\n\n\n\n\n![](compared_calibration.png)\n\nWe could evaluate just how much the calibration has helped by calculating [Brier Skill Score](https://en.wikipedia.org/wiki/Brier_score#Brier_Skill_Score_(BSS)), for example, but quantifying improvement to xG is not our primary focus.\n\n### Revising Expected Points (xPts)\n\nWe set out to evaluate how we could improve xPts (which relies on xG), so let's do that. I'll spare the details of how to calculate xPts because I have a whole separate blog post on that.\n\n\n\n\n\nInstead, let's skip to evaluating\n\n\n\n\n\n\n\n## TODO\n\n[There is evidence](https://twitter.com/Torvaney/status/1623316194936725506) that the current score of a match effects shooting rate, but it's not so clear that it has [an effect on conversion probability](https://kwiatkowski.io/rethinking-shots).\n\n## Conclustion\n\nSo, we've shown that model calibration improves the accuracy of xPts. We achieved this by tuning xG with game state. Depending on the context, if one finds that a variable improves model performance when accounted for in a post-training calibration step. one might consider adding said variable as an additional feature for training. However, if one only has access to a model's output, as we did here with xG, then calibration can be a really sound choice.\n\nWhile I would not suggest that xG models should be modified to take game state as an additional feature since it would compromise the conceptual integrity of such a model, one might choose\n\n*\"Why should accounting for game state create a more accurate set of xPts? Doesn't xG already directly capture the fact that teams trailing in a match may be taking more, lower quality shots?\"* Well, there are at least two confounding factors that immediately come to mind:\n\n1.  Players on the trailing team may be taking more off-balance or rushed shots that they would not otherwise take. Traditional xG model, which do not account for body pose or footedness, do not capture this kind of \"desperateness\".\n2.  Players on teams that fall behind their opponents tend to have less finishing skill. Lower finishing skill generally manifests in worse goal conversion rates. Thust, the xG of shots taken by such players may tend to overrate their actual number of goals scored.\n\nA picture is worth a thousand words.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}